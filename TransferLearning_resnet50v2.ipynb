{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-08 21:03:41.775100: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-08 21:03:41.799183: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-08 21:03:41.834189: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-08 21:03:41.843109: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-08 21:03:41.869750: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-08 21:03:43.085997: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5193 images belonging to 4 classes.\n",
      "Found 1484 images belonging to 4 classes.\n",
      "Found 740 images belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-08 21:03:45.136344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21783 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:af:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/esidserver/miniforge3/envs/tf/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1725804238.854390 3135591 service.cc:146] XLA service 0x7def00015440 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1725804238.854456 3135591 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-09-08 21:03:59.178281: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-09-08 21:04:00.497591: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8902\n",
      "2024-09-08 21:04:01.763587: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5887', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-09-08 21:04:01.785496: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5887', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2024-09-08 21:04:02.015258: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5687', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-09-08 21:04:02.275022: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5887', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2024-09-08 21:04:02.298610: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5680', 176 bytes spill stores, 468 bytes spill loads\n",
      "\n",
      "2024-09-08 21:04:02.329003: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5887', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2024-09-08 21:04:02.421172: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5687', 136 bytes spill stores, 136 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/163\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m46:05\u001b[0m 17s/step - accuracy: 0.3438 - loss: 1.4298"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1725804246.220508 3135591 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m152/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m4s\u001b[0m 377ms/step - accuracy: 0.2932 - loss: 1.3798"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-08 21:05:05.964403: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5687', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - accuracy: 0.2940 - loss: 1.3790"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-08 21:05:21.207939: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1719', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 490ms/step - accuracy: 0.2942 - loss: 1.3788 - val_accuracy: 0.4400 - val_loss: 1.3130\n",
      "Epoch 2/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 397ms/step - accuracy: 0.3500 - loss: 1.3328 - val_accuracy: 0.4461 - val_loss: 1.2692\n",
      "Epoch 3/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 398ms/step - accuracy: 0.4032 - loss: 1.2872 - val_accuracy: 0.4036 - val_loss: 1.2447\n",
      "Epoch 4/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 404ms/step - accuracy: 0.4387 - loss: 1.2506 - val_accuracy: 0.4555 - val_loss: 1.2061\n",
      "Epoch 5/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 398ms/step - accuracy: 0.4307 - loss: 1.2414 - val_accuracy: 0.4791 - val_loss: 1.1801\n",
      "Epoch 6/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 386ms/step - accuracy: 0.4509 - loss: 1.2087 - val_accuracy: 0.5283 - val_loss: 1.1639\n",
      "Epoch 7/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 386ms/step - accuracy: 0.4547 - loss: 1.1978 - val_accuracy: 0.4987 - val_loss: 1.1243\n",
      "Epoch 8/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 366ms/step - accuracy: 0.4865 - loss: 1.1608 - val_accuracy: 0.3915 - val_loss: 1.2001\n",
      "Epoch 9/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 384ms/step - accuracy: 0.4393 - loss: 1.1905 - val_accuracy: 0.5061 - val_loss: 1.1224\n",
      "Epoch 10/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.4658 - loss: 1.1639 - val_accuracy: 0.4872 - val_loss: 1.1330\n",
      "Epoch 11/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 400ms/step - accuracy: 0.4772 - loss: 1.1483 - val_accuracy: 0.5061 - val_loss: 1.0836\n",
      "Epoch 12/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 374ms/step - accuracy: 0.4764 - loss: 1.1341 - val_accuracy: 0.5155 - val_loss: 1.1068\n",
      "Epoch 13/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 378ms/step - accuracy: 0.4962 - loss: 1.1300 - val_accuracy: 0.5465 - val_loss: 1.0716\n",
      "Epoch 14/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.4879 - loss: 1.1270 - val_accuracy: 0.5580 - val_loss: 1.1248\n",
      "Epoch 15/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 372ms/step - accuracy: 0.4809 - loss: 1.1252 - val_accuracy: 0.5216 - val_loss: 1.1066\n",
      "Epoch 16/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 403ms/step - accuracy: 0.4854 - loss: 1.1120 - val_accuracy: 0.5391 - val_loss: 1.0629\n",
      "Epoch 17/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 394ms/step - accuracy: 0.4845 - loss: 1.1199 - val_accuracy: 0.5323 - val_loss: 1.0549\n",
      "Epoch 18/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 399ms/step - accuracy: 0.4735 - loss: 1.1224 - val_accuracy: 0.5573 - val_loss: 1.0440\n",
      "Epoch 19/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 371ms/step - accuracy: 0.5021 - loss: 1.1070 - val_accuracy: 0.5101 - val_loss: 1.0708\n",
      "Epoch 20/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 370ms/step - accuracy: 0.5012 - loss: 1.0887 - val_accuracy: 0.5822 - val_loss: 1.0628\n",
      "Epoch 21/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 374ms/step - accuracy: 0.4956 - loss: 1.1086 - val_accuracy: 0.5411 - val_loss: 1.0799\n",
      "Epoch 22/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 372ms/step - accuracy: 0.5061 - loss: 1.0979 - val_accuracy: 0.5721 - val_loss: 1.0543\n",
      "Epoch 23/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 376ms/step - accuracy: 0.4991 - loss: 1.0961 - val_accuracy: 0.5714 - val_loss: 1.0092\n",
      "Epoch 24/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 388ms/step - accuracy: 0.5119 - loss: 1.0833 - val_accuracy: 0.5546 - val_loss: 1.0748\n",
      "Epoch 25/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 367ms/step - accuracy: 0.4963 - loss: 1.1074 - val_accuracy: 0.5263 - val_loss: 1.0511\n",
      "Epoch 26/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 373ms/step - accuracy: 0.5078 - loss: 1.1011 - val_accuracy: 0.5802 - val_loss: 1.0242\n",
      "Epoch 27/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 375ms/step - accuracy: 0.5041 - loss: 1.0839 - val_accuracy: 0.5431 - val_loss: 1.0245\n",
      "Epoch 28/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 374ms/step - accuracy: 0.5211 - loss: 1.0810 - val_accuracy: 0.5539 - val_loss: 1.0025\n",
      "Epoch 29/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 369ms/step - accuracy: 0.4961 - loss: 1.0908 - val_accuracy: 0.5681 - val_loss: 0.9960\n",
      "Epoch 30/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 373ms/step - accuracy: 0.5151 - loss: 1.0784 - val_accuracy: 0.5404 - val_loss: 1.0355\n",
      "Epoch 31/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 396ms/step - accuracy: 0.5216 - loss: 1.0737 - val_accuracy: 0.5451 - val_loss: 1.0237\n",
      "Epoch 32/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 372ms/step - accuracy: 0.5035 - loss: 1.0822 - val_accuracy: 0.5458 - val_loss: 1.0527\n",
      "Epoch 33/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 390ms/step - accuracy: 0.5137 - loss: 1.0856 - val_accuracy: 0.5640 - val_loss: 0.9824\n",
      "Epoch 34/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 368ms/step - accuracy: 0.5056 - loss: 1.0717 - val_accuracy: 0.5809 - val_loss: 0.9853\n",
      "Epoch 35/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.5128 - loss: 1.0617 - val_accuracy: 0.5815 - val_loss: 0.9854\n",
      "Epoch 36/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 371ms/step - accuracy: 0.5144 - loss: 1.0819 - val_accuracy: 0.5889 - val_loss: 0.9787\n",
      "Epoch 37/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 366ms/step - accuracy: 0.5215 - loss: 1.0561 - val_accuracy: 0.5519 - val_loss: 0.9903\n",
      "Epoch 38/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.5374 - loss: 1.0476 - val_accuracy: 0.5748 - val_loss: 0.9945\n",
      "Epoch 39/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.5192 - loss: 1.0600 - val_accuracy: 0.5472 - val_loss: 0.9963\n",
      "Epoch 40/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 373ms/step - accuracy: 0.5221 - loss: 1.0608 - val_accuracy: 0.5593 - val_loss: 0.9924\n",
      "Epoch 41/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.5207 - loss: 1.0679 - val_accuracy: 0.5997 - val_loss: 0.9945\n",
      "Epoch 42/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 370ms/step - accuracy: 0.5128 - loss: 1.0754 - val_accuracy: 0.5943 - val_loss: 0.9741\n",
      "Epoch 43/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 377ms/step - accuracy: 0.5234 - loss: 1.0547 - val_accuracy: 0.5970 - val_loss: 0.9609\n",
      "Epoch 44/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 375ms/step - accuracy: 0.5273 - loss: 1.0492 - val_accuracy: 0.6112 - val_loss: 0.9618\n",
      "Epoch 45/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 362ms/step - accuracy: 0.5319 - loss: 1.0412 - val_accuracy: 0.6065 - val_loss: 0.9782\n",
      "Epoch 46/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 383ms/step - accuracy: 0.5339 - loss: 1.0535 - val_accuracy: 0.6024 - val_loss: 0.9543\n",
      "Epoch 47/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.5323 - loss: 1.0419 - val_accuracy: 0.5836 - val_loss: 0.9971\n",
      "Epoch 48/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 366ms/step - accuracy: 0.5341 - loss: 1.0458 - val_accuracy: 0.5748 - val_loss: 1.0263\n",
      "Epoch 49/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 366ms/step - accuracy: 0.5322 - loss: 1.0504 - val_accuracy: 0.6146 - val_loss: 0.9590\n",
      "Epoch 50/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 373ms/step - accuracy: 0.5257 - loss: 1.0444 - val_accuracy: 0.5950 - val_loss: 0.9799\n",
      "Epoch 51/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 375ms/step - accuracy: 0.5367 - loss: 1.0385 - val_accuracy: 0.5526 - val_loss: 0.9768\n",
      "Epoch 52/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.5342 - loss: 1.0526 - val_accuracy: 0.6018 - val_loss: 0.9623\n",
      "Epoch 53/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 367ms/step - accuracy: 0.5323 - loss: 1.0594 - val_accuracy: 0.5957 - val_loss: 0.9500\n",
      "Epoch 54/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 370ms/step - accuracy: 0.5534 - loss: 1.0364 - val_accuracy: 0.5991 - val_loss: 0.9468\n",
      "Epoch 55/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 368ms/step - accuracy: 0.5448 - loss: 1.0369 - val_accuracy: 0.5627 - val_loss: 0.9752\n",
      "Epoch 56/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.5610 - loss: 1.0286 - val_accuracy: 0.5863 - val_loss: 0.9598\n",
      "Epoch 57/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 366ms/step - accuracy: 0.5343 - loss: 1.0509 - val_accuracy: 0.6146 - val_loss: 0.9599\n",
      "Epoch 58/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 361ms/step - accuracy: 0.5486 - loss: 1.0089 - val_accuracy: 0.5620 - val_loss: 0.9629\n",
      "Epoch 59/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 367ms/step - accuracy: 0.5440 - loss: 1.0360 - val_accuracy: 0.6004 - val_loss: 0.9498\n",
      "Epoch 60/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 369ms/step - accuracy: 0.5388 - loss: 1.0240 - val_accuracy: 0.6213 - val_loss: 0.9507\n",
      "Epoch 61/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 370ms/step - accuracy: 0.5549 - loss: 1.0211 - val_accuracy: 0.6179 - val_loss: 0.9608\n",
      "Epoch 62/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 376ms/step - accuracy: 0.5433 - loss: 1.0356 - val_accuracy: 0.5997 - val_loss: 0.9450\n",
      "Epoch 63/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 376ms/step - accuracy: 0.5196 - loss: 1.0428 - val_accuracy: 0.6125 - val_loss: 0.9345\n",
      "Epoch 64/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 370ms/step - accuracy: 0.5454 - loss: 1.0161 - val_accuracy: 0.5943 - val_loss: 0.9437\n",
      "Epoch 65/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 373ms/step - accuracy: 0.5313 - loss: 1.0426 - val_accuracy: 0.5957 - val_loss: 1.0022\n",
      "Epoch 66/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 368ms/step - accuracy: 0.5514 - loss: 1.0275 - val_accuracy: 0.6220 - val_loss: 0.9450\n",
      "Epoch 67/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.5622 - loss: 1.0083 - val_accuracy: 0.5640 - val_loss: 0.9912\n",
      "Epoch 68/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 370ms/step - accuracy: 0.5394 - loss: 1.0320 - val_accuracy: 0.5640 - val_loss: 0.9843\n",
      "Epoch 69/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 377ms/step - accuracy: 0.5339 - loss: 1.0300 - val_accuracy: 0.6132 - val_loss: 0.9344\n",
      "Epoch 70/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 378ms/step - accuracy: 0.5303 - loss: 1.0354 - val_accuracy: 0.5863 - val_loss: 0.9467\n",
      "Epoch 71/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 374ms/step - accuracy: 0.5559 - loss: 1.0145 - val_accuracy: 0.6193 - val_loss: 0.9348\n",
      "Epoch 72/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 367ms/step - accuracy: 0.5561 - loss: 1.0071 - val_accuracy: 0.5647 - val_loss: 0.9621\n",
      "Epoch 73/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 370ms/step - accuracy: 0.5491 - loss: 1.0286 - val_accuracy: 0.5519 - val_loss: 1.0042\n",
      "Epoch 74/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 356ms/step - accuracy: 0.5274 - loss: 1.0434 - val_accuracy: 0.6018 - val_loss: 0.9466\n",
      "Epoch 75/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 370ms/step - accuracy: 0.5417 - loss: 1.0211 - val_accuracy: 0.6139 - val_loss: 0.9285\n",
      "Epoch 76/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.5622 - loss: 1.0072 - val_accuracy: 0.5896 - val_loss: 0.9529\n",
      "Epoch 77/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 366ms/step - accuracy: 0.5401 - loss: 1.0210 - val_accuracy: 0.5559 - val_loss: 0.9833\n",
      "Epoch 78/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 372ms/step - accuracy: 0.5614 - loss: 1.0174 - val_accuracy: 0.6105 - val_loss: 0.9254\n",
      "Epoch 79/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.5652 - loss: 1.0051 - val_accuracy: 0.6199 - val_loss: 0.9490\n",
      "Epoch 80/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 361ms/step - accuracy: 0.5541 - loss: 1.0295 - val_accuracy: 0.5910 - val_loss: 0.9435\n",
      "Epoch 81/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 374ms/step - accuracy: 0.5472 - loss: 1.0183 - val_accuracy: 0.6071 - val_loss: 0.9314\n",
      "Epoch 82/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 370ms/step - accuracy: 0.5430 - loss: 1.0159 - val_accuracy: 0.5687 - val_loss: 0.9577\n",
      "Epoch 83/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 371ms/step - accuracy: 0.5733 - loss: 0.9993 - val_accuracy: 0.6166 - val_loss: 0.9218\n",
      "Epoch 84/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 372ms/step - accuracy: 0.5404 - loss: 1.0267 - val_accuracy: 0.5896 - val_loss: 0.9327\n",
      "Epoch 85/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 376ms/step - accuracy: 0.5690 - loss: 0.9922 - val_accuracy: 0.6119 - val_loss: 0.9320\n",
      "Epoch 86/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 376ms/step - accuracy: 0.5567 - loss: 1.0069 - val_accuracy: 0.5923 - val_loss: 0.9341\n",
      "Epoch 87/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 375ms/step - accuracy: 0.5388 - loss: 1.0270 - val_accuracy: 0.5896 - val_loss: 0.9470\n",
      "Epoch 88/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 370ms/step - accuracy: 0.5413 - loss: 1.0275 - val_accuracy: 0.6146 - val_loss: 0.9550\n",
      "Epoch 89/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.5525 - loss: 1.0013 - val_accuracy: 0.5910 - val_loss: 0.9444\n",
      "Epoch 90/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.5482 - loss: 1.0233 - val_accuracy: 0.5883 - val_loss: 0.9502\n",
      "Epoch 91/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 373ms/step - accuracy: 0.5745 - loss: 0.9933 - val_accuracy: 0.6233 - val_loss: 0.9263\n",
      "Epoch 92/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 372ms/step - accuracy: 0.5612 - loss: 0.9901 - val_accuracy: 0.5573 - val_loss: 0.9721\n",
      "Epoch 93/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 378ms/step - accuracy: 0.5491 - loss: 1.0265 - val_accuracy: 0.5647 - val_loss: 0.9598\n",
      "Epoch 94/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.5561 - loss: 1.0100 - val_accuracy: 0.5674 - val_loss: 0.9630\n",
      "Epoch 95/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 374ms/step - accuracy: 0.5762 - loss: 0.9919 - val_accuracy: 0.6253 - val_loss: 0.9178\n",
      "Epoch 96/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 372ms/step - accuracy: 0.5509 - loss: 1.0014 - val_accuracy: 0.5916 - val_loss: 0.9386\n",
      "Epoch 97/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 362ms/step - accuracy: 0.5474 - loss: 0.9922 - val_accuracy: 0.5876 - val_loss: 0.9481\n",
      "Epoch 98/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 373ms/step - accuracy: 0.5545 - loss: 1.0039 - val_accuracy: 0.5957 - val_loss: 0.9285\n",
      "Epoch 99/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.5696 - loss: 0.9854 - val_accuracy: 0.6233 - val_loss: 0.9207\n",
      "Epoch 100/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 377ms/step - accuracy: 0.5746 - loss: 0.9897 - val_accuracy: 0.6348 - val_loss: 0.9280\n",
      "Epoch 101/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 372ms/step - accuracy: 0.5651 - loss: 0.9987 - val_accuracy: 0.6334 - val_loss: 0.9147\n",
      "Epoch 102/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 359ms/step - accuracy: 0.5702 - loss: 1.0051 - val_accuracy: 0.6226 - val_loss: 0.9219\n",
      "Epoch 103/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 367ms/step - accuracy: 0.5612 - loss: 1.0062 - val_accuracy: 0.6112 - val_loss: 0.9428\n",
      "Epoch 104/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 367ms/step - accuracy: 0.5653 - loss: 1.0025 - val_accuracy: 0.6132 - val_loss: 0.9141\n",
      "Epoch 105/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.5588 - loss: 0.9942 - val_accuracy: 0.6119 - val_loss: 0.9271\n",
      "Epoch 106/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 361ms/step - accuracy: 0.5662 - loss: 0.9979 - val_accuracy: 0.6301 - val_loss: 0.9249\n",
      "Epoch 107/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 369ms/step - accuracy: 0.5607 - loss: 1.0069 - val_accuracy: 0.6186 - val_loss: 0.9127\n",
      "Epoch 108/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.5587 - loss: 0.9910 - val_accuracy: 0.5822 - val_loss: 0.9378\n",
      "Epoch 109/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 383ms/step - accuracy: 0.5631 - loss: 0.9996 - val_accuracy: 0.6125 - val_loss: 0.9116\n",
      "Epoch 110/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 371ms/step - accuracy: 0.5751 - loss: 0.9758 - val_accuracy: 0.6402 - val_loss: 0.9091\n",
      "Epoch 111/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 366ms/step - accuracy: 0.5610 - loss: 0.9895 - val_accuracy: 0.5997 - val_loss: 0.9437\n",
      "Epoch 112/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 380ms/step - accuracy: 0.5561 - loss: 0.9916 - val_accuracy: 0.5984 - val_loss: 0.9286\n",
      "Epoch 113/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.5726 - loss: 0.9796 - val_accuracy: 0.6186 - val_loss: 0.9136\n",
      "Epoch 114/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 370ms/step - accuracy: 0.5640 - loss: 0.9962 - val_accuracy: 0.6314 - val_loss: 0.9038\n",
      "Epoch 115/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 370ms/step - accuracy: 0.5778 - loss: 0.9726 - val_accuracy: 0.5836 - val_loss: 0.9409\n",
      "Epoch 116/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.5661 - loss: 0.9932 - val_accuracy: 0.6018 - val_loss: 0.9214\n",
      "Epoch 117/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 368ms/step - accuracy: 0.5643 - loss: 0.9976 - val_accuracy: 0.6247 - val_loss: 0.9120\n",
      "Epoch 118/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.5606 - loss: 0.9981 - val_accuracy: 0.6125 - val_loss: 0.9087\n",
      "Epoch 119/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 374ms/step - accuracy: 0.5658 - loss: 0.9879 - val_accuracy: 0.6368 - val_loss: 0.9082\n",
      "Epoch 120/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 366ms/step - accuracy: 0.5681 - loss: 0.9934 - val_accuracy: 0.5883 - val_loss: 0.9451\n",
      "Epoch 121/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 371ms/step - accuracy: 0.5757 - loss: 0.9864 - val_accuracy: 0.6125 - val_loss: 0.9232\n",
      "Epoch 122/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 376ms/step - accuracy: 0.5769 - loss: 0.9860 - val_accuracy: 0.5916 - val_loss: 0.9380\n",
      "Epoch 123/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 372ms/step - accuracy: 0.5830 - loss: 0.9732 - val_accuracy: 0.6354 - val_loss: 0.8935\n",
      "Epoch 124/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 369ms/step - accuracy: 0.5663 - loss: 0.9755 - val_accuracy: 0.6098 - val_loss: 0.9096\n",
      "Epoch 125/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 367ms/step - accuracy: 0.5695 - loss: 0.9875 - val_accuracy: 0.6334 - val_loss: 0.8945\n",
      "Epoch 126/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 366ms/step - accuracy: 0.5693 - loss: 1.0057 - val_accuracy: 0.6307 - val_loss: 0.8924\n",
      "Epoch 127/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.5655 - loss: 0.9876 - val_accuracy: 0.6240 - val_loss: 0.8999\n",
      "Epoch 128/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 369ms/step - accuracy: 0.5899 - loss: 0.9725 - val_accuracy: 0.6361 - val_loss: 0.9253\n",
      "Epoch 129/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 375ms/step - accuracy: 0.5734 - loss: 0.9857 - val_accuracy: 0.6119 - val_loss: 0.9030\n",
      "Epoch 130/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.5759 - loss: 0.9939 - val_accuracy: 0.5984 - val_loss: 0.9261\n",
      "Epoch 131/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 376ms/step - accuracy: 0.5678 - loss: 0.9779 - val_accuracy: 0.6429 - val_loss: 0.9019\n",
      "Epoch 132/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 361ms/step - accuracy: 0.5792 - loss: 0.9709 - val_accuracy: 0.6119 - val_loss: 0.9016\n",
      "Epoch 133/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 367ms/step - accuracy: 0.5688 - loss: 0.9842 - val_accuracy: 0.6092 - val_loss: 0.9072\n",
      "Epoch 134/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 375ms/step - accuracy: 0.5741 - loss: 0.9692 - val_accuracy: 0.6402 - val_loss: 0.8864\n",
      "Epoch 135/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 371ms/step - accuracy: 0.5663 - loss: 0.9640 - val_accuracy: 0.6038 - val_loss: 0.9137\n",
      "Epoch 136/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 370ms/step - accuracy: 0.5766 - loss: 0.9804 - val_accuracy: 0.6327 - val_loss: 0.8874\n",
      "Epoch 137/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 383ms/step - accuracy: 0.5846 - loss: 0.9776 - val_accuracy: 0.6381 - val_loss: 0.8842\n",
      "Epoch 138/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 385ms/step - accuracy: 0.5815 - loss: 0.9734 - val_accuracy: 0.6381 - val_loss: 0.9128\n",
      "Epoch 139/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 372ms/step - accuracy: 0.5779 - loss: 0.9622 - val_accuracy: 0.5957 - val_loss: 0.9286\n",
      "Epoch 140/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 379ms/step - accuracy: 0.5675 - loss: 0.9843 - val_accuracy: 0.6368 - val_loss: 0.8942\n",
      "Epoch 141/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 370ms/step - accuracy: 0.5881 - loss: 0.9735 - val_accuracy: 0.5809 - val_loss: 0.9436\n",
      "Epoch 142/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 371ms/step - accuracy: 0.5736 - loss: 0.9636 - val_accuracy: 0.6206 - val_loss: 0.8942\n",
      "Epoch 143/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 365ms/step - accuracy: 0.5671 - loss: 0.9714 - val_accuracy: 0.6294 - val_loss: 0.8960\n",
      "Epoch 144/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.5794 - loss: 0.9817 - val_accuracy: 0.6307 - val_loss: 0.8867\n",
      "Epoch 145/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.5649 - loss: 0.9809 - val_accuracy: 0.6381 - val_loss: 0.8905\n",
      "Epoch 146/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 362ms/step - accuracy: 0.5723 - loss: 0.9731 - val_accuracy: 0.6199 - val_loss: 0.8921\n",
      "Epoch 147/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.5806 - loss: 0.9813 - val_accuracy: 0.6247 - val_loss: 0.8920\n",
      "Epoch 148/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 370ms/step - accuracy: 0.5759 - loss: 0.9559 - val_accuracy: 0.6449 - val_loss: 0.9189\n",
      "Epoch 149/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 370ms/step - accuracy: 0.5744 - loss: 0.9774 - val_accuracy: 0.6058 - val_loss: 0.9338\n",
      "Epoch 150/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 361ms/step - accuracy: 0.5443 - loss: 1.0080 - val_accuracy: 0.6092 - val_loss: 0.9142\n",
      "Epoch 151/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.5922 - loss: 0.9613 - val_accuracy: 0.6375 - val_loss: 0.8894\n",
      "Epoch 152/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 371ms/step - accuracy: 0.5624 - loss: 0.9799 - val_accuracy: 0.6267 - val_loss: 0.8949\n",
      "Epoch 153/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 370ms/step - accuracy: 0.5760 - loss: 0.9696 - val_accuracy: 0.6280 - val_loss: 0.8870\n",
      "Epoch 154/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 379ms/step - accuracy: 0.5824 - loss: 0.9768 - val_accuracy: 0.6152 - val_loss: 0.8956\n",
      "Epoch 155/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 374ms/step - accuracy: 0.5812 - loss: 0.9844 - val_accuracy: 0.6482 - val_loss: 0.8776\n",
      "Epoch 156/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.5937 - loss: 0.9683 - val_accuracy: 0.6361 - val_loss: 0.8933\n",
      "Epoch 157/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 372ms/step - accuracy: 0.5718 - loss: 0.9676 - val_accuracy: 0.6402 - val_loss: 0.8804\n",
      "Epoch 158/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 374ms/step - accuracy: 0.5870 - loss: 0.9551 - val_accuracy: 0.6469 - val_loss: 0.8719\n",
      "Epoch 159/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 374ms/step - accuracy: 0.5812 - loss: 0.9624 - val_accuracy: 0.6354 - val_loss: 0.8809\n",
      "Epoch 160/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 370ms/step - accuracy: 0.5664 - loss: 0.9744 - val_accuracy: 0.6186 - val_loss: 0.8895\n",
      "Epoch 161/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.5843 - loss: 0.9762 - val_accuracy: 0.6226 - val_loss: 0.8851\n",
      "Epoch 162/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 367ms/step - accuracy: 0.5825 - loss: 0.9703 - val_accuracy: 0.6442 - val_loss: 0.8767\n",
      "Epoch 163/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.5847 - loss: 0.9729 - val_accuracy: 0.6294 - val_loss: 0.8850\n",
      "Epoch 164/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 361ms/step - accuracy: 0.5607 - loss: 0.9852 - val_accuracy: 0.6287 - val_loss: 0.8876\n",
      "Epoch 165/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 377ms/step - accuracy: 0.5738 - loss: 0.9719 - val_accuracy: 0.6240 - val_loss: 0.9397\n",
      "Epoch 166/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.5848 - loss: 0.9761 - val_accuracy: 0.6496 - val_loss: 0.8908\n",
      "Epoch 167/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 374ms/step - accuracy: 0.5939 - loss: 0.9699 - val_accuracy: 0.6071 - val_loss: 0.9036\n",
      "Epoch 168/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 361ms/step - accuracy: 0.5751 - loss: 0.9748 - val_accuracy: 0.6354 - val_loss: 0.8797\n",
      "Epoch 169/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 376ms/step - accuracy: 0.5883 - loss: 0.9585 - val_accuracy: 0.6516 - val_loss: 0.8653\n",
      "Epoch 170/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.5892 - loss: 0.9660 - val_accuracy: 0.6280 - val_loss: 0.8798\n",
      "Epoch 171/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.5900 - loss: 0.9467 - val_accuracy: 0.6065 - val_loss: 0.9048\n",
      "Epoch 172/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 372ms/step - accuracy: 0.5726 - loss: 0.9643 - val_accuracy: 0.6112 - val_loss: 0.9154\n",
      "Epoch 173/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 378ms/step - accuracy: 0.5767 - loss: 0.9629 - val_accuracy: 0.6577 - val_loss: 0.8631\n",
      "Epoch 174/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 376ms/step - accuracy: 0.5757 - loss: 0.9728 - val_accuracy: 0.6496 - val_loss: 0.8612\n",
      "Epoch 175/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 355ms/step - accuracy: 0.5725 - loss: 0.9693 - val_accuracy: 0.6247 - val_loss: 0.8903\n",
      "Epoch 176/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 366ms/step - accuracy: 0.5803 - loss: 0.9649 - val_accuracy: 0.6462 - val_loss: 0.8714\n",
      "Epoch 177/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.5821 - loss: 0.9654 - val_accuracy: 0.6274 - val_loss: 0.8802\n",
      "Epoch 178/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.5912 - loss: 0.9536 - val_accuracy: 0.6233 - val_loss: 0.8937\n",
      "Epoch 179/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.5827 - loss: 0.9707 - val_accuracy: 0.6152 - val_loss: 0.8928\n",
      "Epoch 180/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 361ms/step - accuracy: 0.5768 - loss: 0.9795 - val_accuracy: 0.6327 - val_loss: 0.8984\n",
      "Epoch 181/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.5899 - loss: 0.9649 - val_accuracy: 0.6267 - val_loss: 0.8789\n",
      "Epoch 182/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.5849 - loss: 0.9488 - val_accuracy: 0.6240 - val_loss: 0.8873\n",
      "Epoch 183/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.5873 - loss: 0.9710 - val_accuracy: 0.6287 - val_loss: 0.8779\n",
      "Epoch 184/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.5827 - loss: 0.9645 - val_accuracy: 0.5815 - val_loss: 0.9387\n",
      "Epoch 185/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 362ms/step - accuracy: 0.5855 - loss: 0.9538 - val_accuracy: 0.6489 - val_loss: 0.8733\n",
      "Epoch 186/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 361ms/step - accuracy: 0.5761 - loss: 0.9622 - val_accuracy: 0.5977 - val_loss: 0.9215\n",
      "Epoch 187/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 368ms/step - accuracy: 0.5806 - loss: 0.9715 - val_accuracy: 0.6024 - val_loss: 0.9260\n",
      "Epoch 188/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 366ms/step - accuracy: 0.5756 - loss: 0.9733 - val_accuracy: 0.6179 - val_loss: 0.8897\n",
      "Epoch 189/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 375ms/step - accuracy: 0.5841 - loss: 0.9523 - val_accuracy: 0.6550 - val_loss: 0.8594\n",
      "Epoch 190/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 356ms/step - accuracy: 0.5707 - loss: 0.9691 - val_accuracy: 0.6334 - val_loss: 0.8640\n",
      "Epoch 191/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 369ms/step - accuracy: 0.6080 - loss: 0.9338 - val_accuracy: 0.6496 - val_loss: 0.8600\n",
      "Epoch 192/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 377ms/step - accuracy: 0.5874 - loss: 0.9510 - val_accuracy: 0.6415 - val_loss: 0.8566\n",
      "Epoch 193/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 362ms/step - accuracy: 0.5959 - loss: 0.9337 - val_accuracy: 0.6509 - val_loss: 0.8620\n",
      "Epoch 194/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 373ms/step - accuracy: 0.5621 - loss: 0.9725 - val_accuracy: 0.6287 - val_loss: 0.8857\n",
      "Epoch 195/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 370ms/step - accuracy: 0.5966 - loss: 0.9579 - val_accuracy: 0.6543 - val_loss: 0.8646\n",
      "Epoch 196/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 379ms/step - accuracy: 0.5891 - loss: 0.9453 - val_accuracy: 0.6375 - val_loss: 0.8717\n",
      "Epoch 197/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 372ms/step - accuracy: 0.5800 - loss: 0.9589 - val_accuracy: 0.6179 - val_loss: 0.8870\n",
      "Epoch 198/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 366ms/step - accuracy: 0.5999 - loss: 0.9440 - val_accuracy: 0.6193 - val_loss: 0.8857\n",
      "Epoch 199/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 378ms/step - accuracy: 0.5739 - loss: 0.9578 - val_accuracy: 0.6125 - val_loss: 0.8919\n",
      "Epoch 200/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 365ms/step - accuracy: 0.6185 - loss: 0.9263 - val_accuracy: 0.6651 - val_loss: 0.8582\n",
      "Epoch 201/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.5750 - loss: 0.9638 - val_accuracy: 0.6509 - val_loss: 0.8677\n",
      "Epoch 202/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 369ms/step - accuracy: 0.5954 - loss: 0.9461 - val_accuracy: 0.6664 - val_loss: 0.8583\n",
      "Epoch 203/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 374ms/step - accuracy: 0.5903 - loss: 0.9467 - val_accuracy: 0.6368 - val_loss: 0.8770\n",
      "Epoch 204/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.6062 - loss: 0.9331 - val_accuracy: 0.6462 - val_loss: 0.8608\n",
      "Epoch 205/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 376ms/step - accuracy: 0.6069 - loss: 0.9497 - val_accuracy: 0.6435 - val_loss: 0.8617\n",
      "Epoch 206/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 365ms/step - accuracy: 0.5784 - loss: 0.9666 - val_accuracy: 0.6294 - val_loss: 0.8907\n",
      "Epoch 207/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 365ms/step - accuracy: 0.5811 - loss: 0.9512 - val_accuracy: 0.6287 - val_loss: 0.8798\n",
      "Epoch 208/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.5988 - loss: 0.9458 - val_accuracy: 0.6422 - val_loss: 0.8751\n",
      "Epoch 209/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.5785 - loss: 0.9703 - val_accuracy: 0.6301 - val_loss: 0.8805\n",
      "Epoch 210/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.5964 - loss: 0.9400 - val_accuracy: 0.6213 - val_loss: 0.8824\n",
      "Epoch 211/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 361ms/step - accuracy: 0.5854 - loss: 0.9425 - val_accuracy: 0.6375 - val_loss: 0.8581\n",
      "Epoch 212/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 361ms/step - accuracy: 0.5966 - loss: 0.9303 - val_accuracy: 0.6408 - val_loss: 0.8660\n",
      "Epoch 213/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 368ms/step - accuracy: 0.5713 - loss: 0.9526 - val_accuracy: 0.6422 - val_loss: 0.8543\n",
      "Epoch 214/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 355ms/step - accuracy: 0.5849 - loss: 0.9472 - val_accuracy: 0.6233 - val_loss: 0.8836\n",
      "Epoch 215/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.5875 - loss: 0.9737 - val_accuracy: 0.6321 - val_loss: 0.8879\n",
      "Epoch 216/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 359ms/step - accuracy: 0.5832 - loss: 0.9546 - val_accuracy: 0.6354 - val_loss: 0.8673\n",
      "Epoch 217/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 376ms/step - accuracy: 0.5953 - loss: 0.9355 - val_accuracy: 0.6509 - val_loss: 0.8611\n",
      "Epoch 218/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 377ms/step - accuracy: 0.6042 - loss: 0.9410 - val_accuracy: 0.6557 - val_loss: 0.8523\n",
      "Epoch 219/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.5940 - loss: 0.9547 - val_accuracy: 0.6678 - val_loss: 0.8447\n",
      "Epoch 220/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.5968 - loss: 0.9433 - val_accuracy: 0.6496 - val_loss: 0.8453\n",
      "Epoch 221/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.6057 - loss: 0.9358 - val_accuracy: 0.6476 - val_loss: 0.8788\n",
      "Epoch 222/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 366ms/step - accuracy: 0.5907 - loss: 0.9320 - val_accuracy: 0.6563 - val_loss: 0.8554\n",
      "Epoch 223/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.6113 - loss: 0.9428 - val_accuracy: 0.6334 - val_loss: 0.8568\n",
      "Epoch 224/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 354ms/step - accuracy: 0.6030 - loss: 0.9400 - val_accuracy: 0.6503 - val_loss: 0.8782\n",
      "Epoch 225/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 376ms/step - accuracy: 0.6006 - loss: 0.9400 - val_accuracy: 0.6429 - val_loss: 0.8692\n",
      "Epoch 226/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 382ms/step - accuracy: 0.6038 - loss: 0.9365 - val_accuracy: 0.6604 - val_loss: 0.8428\n",
      "Epoch 227/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 369ms/step - accuracy: 0.5846 - loss: 0.9501 - val_accuracy: 0.6476 - val_loss: 0.8694\n",
      "Epoch 228/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.5881 - loss: 0.9553 - val_accuracy: 0.6199 - val_loss: 0.8819\n",
      "Epoch 229/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 361ms/step - accuracy: 0.5912 - loss: 0.9500 - val_accuracy: 0.6435 - val_loss: 0.8490\n",
      "Epoch 230/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.5932 - loss: 0.9264 - val_accuracy: 0.6617 - val_loss: 0.8547\n",
      "Epoch 231/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 368ms/step - accuracy: 0.6039 - loss: 0.9403 - val_accuracy: 0.6624 - val_loss: 0.8562\n",
      "Epoch 232/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.5768 - loss: 0.9606 - val_accuracy: 0.6705 - val_loss: 0.8607\n",
      "Epoch 233/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 373ms/step - accuracy: 0.5934 - loss: 0.9446 - val_accuracy: 0.6516 - val_loss: 0.8465\n",
      "Epoch 234/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.5854 - loss: 0.9574 - val_accuracy: 0.6745 - val_loss: 0.8447\n",
      "Epoch 235/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.5878 - loss: 0.9626 - val_accuracy: 0.6280 - val_loss: 0.8729\n",
      "Epoch 236/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 366ms/step - accuracy: 0.6008 - loss: 0.9363 - val_accuracy: 0.6388 - val_loss: 0.8545\n",
      "Epoch 237/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.5904 - loss: 0.9271 - val_accuracy: 0.6611 - val_loss: 0.8531\n",
      "Epoch 238/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 367ms/step - accuracy: 0.5955 - loss: 0.9490 - val_accuracy: 0.5997 - val_loss: 0.9097\n",
      "Epoch 239/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 374ms/step - accuracy: 0.5772 - loss: 0.9440 - val_accuracy: 0.6408 - val_loss: 0.8567\n",
      "Epoch 240/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 374ms/step - accuracy: 0.5880 - loss: 0.9591 - val_accuracy: 0.6590 - val_loss: 0.8429\n",
      "Epoch 241/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 372ms/step - accuracy: 0.5993 - loss: 0.9272 - val_accuracy: 0.6658 - val_loss: 0.8511\n",
      "Epoch 242/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.5964 - loss: 0.9337 - val_accuracy: 0.5991 - val_loss: 0.9006\n",
      "Epoch 243/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 362ms/step - accuracy: 0.6005 - loss: 0.9477 - val_accuracy: 0.6341 - val_loss: 0.8589\n",
      "Epoch 244/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 362ms/step - accuracy: 0.5971 - loss: 0.9193 - val_accuracy: 0.6449 - val_loss: 0.8430\n",
      "Epoch 245/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 370ms/step - accuracy: 0.6033 - loss: 0.9191 - val_accuracy: 0.6435 - val_loss: 0.8510\n",
      "Epoch 246/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.6034 - loss: 0.9299 - val_accuracy: 0.6584 - val_loss: 0.8474\n",
      "Epoch 247/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.6043 - loss: 0.9326 - val_accuracy: 0.6301 - val_loss: 0.8887\n",
      "Epoch 248/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.5880 - loss: 0.9438 - val_accuracy: 0.6146 - val_loss: 0.8969\n",
      "Epoch 249/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.5944 - loss: 0.9429 - val_accuracy: 0.6429 - val_loss: 0.8727\n",
      "Epoch 250/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 378ms/step - accuracy: 0.5807 - loss: 0.9576 - val_accuracy: 0.6570 - val_loss: 0.8343\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 01:26:50.081450: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_15690', 76 bytes spill stores, 76 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 632ms/step - accuracy: 0.3793 - loss: 41.3927 - val_accuracy: 0.2487 - val_loss: 32.1373\n",
      "Epoch 2/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 365ms/step - accuracy: 0.7471 - loss: 1.5658 - val_accuracy: 0.2487 - val_loss: 48.4284\n",
      "Epoch 3/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 362ms/step - accuracy: 0.8172 - loss: 0.8158 - val_accuracy: 0.2487 - val_loss: 54.4175\n",
      "Epoch 4/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 356ms/step - accuracy: 0.8587 - loss: 0.5577 - val_accuracy: 0.2493 - val_loss: 27.7615\n",
      "Epoch 5/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.8801 - loss: 0.4077 - val_accuracy: 0.3646 - val_loss: 11.5682\n",
      "Epoch 6/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 355ms/step - accuracy: 0.8956 - loss: 0.3434 - val_accuracy: 0.6954 - val_loss: 2.2457\n",
      "Epoch 7/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 371ms/step - accuracy: 0.9082 - loss: 0.2823 - val_accuracy: 0.8632 - val_loss: 0.4820\n",
      "Epoch 8/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 381ms/step - accuracy: 0.9195 - loss: 0.3086 - val_accuracy: 0.9292 - val_loss: 0.1931\n",
      "Epoch 9/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 366ms/step - accuracy: 0.9392 - loss: 0.1783 - val_accuracy: 0.9643 - val_loss: 0.1301\n",
      "Epoch 10/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 378ms/step - accuracy: 0.9460 - loss: 0.1526 - val_accuracy: 0.9602 - val_loss: 0.1121\n",
      "Epoch 11/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 374ms/step - accuracy: 0.9476 - loss: 0.1678 - val_accuracy: 0.9650 - val_loss: 0.0977\n",
      "Epoch 12/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.9556 - loss: 0.1429 - val_accuracy: 0.9677 - val_loss: 0.0857\n",
      "Epoch 13/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 362ms/step - accuracy: 0.9647 - loss: 0.1104 - val_accuracy: 0.9656 - val_loss: 0.1041\n",
      "Epoch 14/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.9665 - loss: 0.1133 - val_accuracy: 0.9744 - val_loss: 0.0790\n",
      "Epoch 15/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 362ms/step - accuracy: 0.9693 - loss: 0.0992 - val_accuracy: 0.9757 - val_loss: 0.0708\n",
      "Epoch 16/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.9657 - loss: 0.1058 - val_accuracy: 0.9764 - val_loss: 0.0726\n",
      "Epoch 17/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 373ms/step - accuracy: 0.9730 - loss: 0.0805 - val_accuracy: 0.9798 - val_loss: 0.0507\n",
      "Epoch 18/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 354ms/step - accuracy: 0.9743 - loss: 0.0731 - val_accuracy: 0.9784 - val_loss: 0.0567\n",
      "Epoch 19/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 362ms/step - accuracy: 0.9778 - loss: 0.0581 - val_accuracy: 0.9825 - val_loss: 0.0530\n",
      "Epoch 20/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 369ms/step - accuracy: 0.9810 - loss: 0.0517 - val_accuracy: 0.9818 - val_loss: 0.0485\n",
      "Epoch 21/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 380ms/step - accuracy: 0.9776 - loss: 0.0636 - val_accuracy: 0.9852 - val_loss: 0.0453\n",
      "Epoch 22/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.9824 - loss: 0.0439 - val_accuracy: 0.9798 - val_loss: 0.0556\n",
      "Epoch 23/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 359ms/step - accuracy: 0.9805 - loss: 0.0521 - val_accuracy: 0.9852 - val_loss: 0.0376\n",
      "Epoch 24/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 381ms/step - accuracy: 0.9836 - loss: 0.0544 - val_accuracy: 0.9872 - val_loss: 0.0374\n",
      "Epoch 25/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 372ms/step - accuracy: 0.9849 - loss: 0.0409 - val_accuracy: 0.9906 - val_loss: 0.0267\n",
      "Epoch 26/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 355ms/step - accuracy: 0.9841 - loss: 0.0452 - val_accuracy: 0.9865 - val_loss: 0.0351\n",
      "Epoch 27/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 368ms/step - accuracy: 0.9892 - loss: 0.0309 - val_accuracy: 0.9879 - val_loss: 0.0258\n",
      "Epoch 28/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 377ms/step - accuracy: 0.9894 - loss: 0.0291 - val_accuracy: 0.9919 - val_loss: 0.0244\n",
      "Epoch 29/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 369ms/step - accuracy: 0.9905 - loss: 0.0317 - val_accuracy: 0.9919 - val_loss: 0.0259\n",
      "Epoch 30/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 356ms/step - accuracy: 0.9907 - loss: 0.0255 - val_accuracy: 0.9919 - val_loss: 0.0315\n",
      "Epoch 31/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 366ms/step - accuracy: 0.9918 - loss: 0.0265 - val_accuracy: 0.9953 - val_loss: 0.0168\n",
      "Epoch 32/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 359ms/step - accuracy: 0.9882 - loss: 0.0310 - val_accuracy: 0.9744 - val_loss: 0.0855\n",
      "Epoch 33/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.9889 - loss: 0.0379 - val_accuracy: 0.9677 - val_loss: 0.1257\n",
      "Epoch 34/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 362ms/step - accuracy: 0.9901 - loss: 0.0300 - val_accuracy: 0.9912 - val_loss: 0.0271\n",
      "Epoch 35/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 355ms/step - accuracy: 0.9881 - loss: 0.0304 - val_accuracy: 0.9899 - val_loss: 0.0353\n",
      "Epoch 36/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 355ms/step - accuracy: 0.9925 - loss: 0.0252 - val_accuracy: 0.9919 - val_loss: 0.0225\n",
      "Epoch 37/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 366ms/step - accuracy: 0.9916 - loss: 0.0206 - val_accuracy: 0.9919 - val_loss: 0.0227\n",
      "Epoch 38/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.9944 - loss: 0.0164 - val_accuracy: 0.9946 - val_loss: 0.0220\n",
      "Epoch 39/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.9901 - loss: 0.0276 - val_accuracy: 0.9879 - val_loss: 0.0451\n",
      "Epoch 40/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 373ms/step - accuracy: 0.9926 - loss: 0.0276 - val_accuracy: 0.9960 - val_loss: 0.0107\n",
      "Epoch 41/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 374ms/step - accuracy: 0.9919 - loss: 0.0232 - val_accuracy: 0.9953 - val_loss: 0.0158\n",
      "Epoch 42/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 361ms/step - accuracy: 0.9919 - loss: 0.0239 - val_accuracy: 0.9919 - val_loss: 0.0207\n",
      "Epoch 43/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.9949 - loss: 0.0125 - val_accuracy: 0.9946 - val_loss: 0.0167\n",
      "Epoch 44/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 359ms/step - accuracy: 0.9921 - loss: 0.0322 - val_accuracy: 0.9919 - val_loss: 0.0207\n",
      "Epoch 45/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 355ms/step - accuracy: 0.9936 - loss: 0.0216 - val_accuracy: 0.9960 - val_loss: 0.0136\n",
      "Epoch 46/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 355ms/step - accuracy: 0.9941 - loss: 0.0262 - val_accuracy: 0.9933 - val_loss: 0.0158\n",
      "Epoch 47/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.9954 - loss: 0.0130 - val_accuracy: 0.9933 - val_loss: 0.0157\n",
      "Epoch 48/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 368ms/step - accuracy: 0.9950 - loss: 0.0128 - val_accuracy: 0.9953 - val_loss: 0.0164\n",
      "Epoch 49/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 369ms/step - accuracy: 0.9944 - loss: 0.0220 - val_accuracy: 0.9960 - val_loss: 0.0100\n",
      "Epoch 50/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 369ms/step - accuracy: 0.9963 - loss: 0.0116 - val_accuracy: 0.9912 - val_loss: 0.0223\n",
      "Epoch 51/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.9906 - loss: 0.0248 - val_accuracy: 0.9939 - val_loss: 0.0198\n",
      "Epoch 52/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.9969 - loss: 0.0141 - val_accuracy: 0.9953 - val_loss: 0.0170\n",
      "Epoch 53/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.9927 - loss: 0.0224 - val_accuracy: 0.9960 - val_loss: 0.0117\n",
      "Epoch 54/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 356ms/step - accuracy: 0.9920 - loss: 0.0202 - val_accuracy: 0.9966 - val_loss: 0.0108\n",
      "Epoch 55/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.9963 - loss: 0.0104 - val_accuracy: 0.9973 - val_loss: 0.0110\n",
      "Epoch 56/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 379ms/step - accuracy: 0.9969 - loss: 0.0087 - val_accuracy: 0.9980 - val_loss: 0.0087\n",
      "Epoch 57/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.9966 - loss: 0.0096 - val_accuracy: 0.9906 - val_loss: 0.0337\n",
      "Epoch 58/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.9968 - loss: 0.0105 - val_accuracy: 0.9980 - val_loss: 0.0094\n",
      "Epoch 59/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.9946 - loss: 0.0159 - val_accuracy: 0.9946 - val_loss: 0.0155\n",
      "Epoch 60/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 356ms/step - accuracy: 0.9949 - loss: 0.0124 - val_accuracy: 0.9892 - val_loss: 0.0359\n",
      "Epoch 61/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 356ms/step - accuracy: 0.9958 - loss: 0.0105 - val_accuracy: 0.9960 - val_loss: 0.0125\n",
      "Epoch 62/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.9944 - loss: 0.0162 - val_accuracy: 0.9973 - val_loss: 0.0084\n",
      "Epoch 63/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 376ms/step - accuracy: 0.9960 - loss: 0.0090 - val_accuracy: 0.9980 - val_loss: 0.0055\n",
      "Epoch 64/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 366ms/step - accuracy: 0.9972 - loss: 0.0085 - val_accuracy: 0.9987 - val_loss: 0.0051\n",
      "Epoch 65/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 374ms/step - accuracy: 0.9947 - loss: 0.0132 - val_accuracy: 0.9953 - val_loss: 0.0146\n",
      "Epoch 66/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 380ms/step - accuracy: 0.9965 - loss: 0.0085 - val_accuracy: 0.9980 - val_loss: 0.0045\n",
      "Epoch 67/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 359ms/step - accuracy: 0.9958 - loss: 0.0114 - val_accuracy: 0.9973 - val_loss: 0.0079\n",
      "Epoch 68/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.9964 - loss: 0.0107 - val_accuracy: 0.9960 - val_loss: 0.0080\n",
      "Epoch 69/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 365ms/step - accuracy: 0.9957 - loss: 0.0084 - val_accuracy: 0.9987 - val_loss: 0.0042\n",
      "Epoch 70/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.9969 - loss: 0.0093 - val_accuracy: 0.9933 - val_loss: 0.0187\n",
      "Epoch 71/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 359ms/step - accuracy: 0.9970 - loss: 0.0107 - val_accuracy: 0.9973 - val_loss: 0.0081\n",
      "Epoch 72/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 369ms/step - accuracy: 0.9965 - loss: 0.0110 - val_accuracy: 0.9919 - val_loss: 0.0288\n",
      "Epoch 73/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 365ms/step - accuracy: 0.9954 - loss: 0.0143 - val_accuracy: 0.9987 - val_loss: 0.0043\n",
      "Epoch 74/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 361ms/step - accuracy: 0.9978 - loss: 0.0075 - val_accuracy: 0.9912 - val_loss: 0.0366\n",
      "Epoch 75/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.9968 - loss: 0.0142 - val_accuracy: 0.9987 - val_loss: 0.0046\n",
      "Epoch 76/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 349ms/step - accuracy: 0.9967 - loss: 0.0081 - val_accuracy: 0.9926 - val_loss: 0.0157\n",
      "Epoch 77/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.9981 - loss: 0.0067 - val_accuracy: 0.9966 - val_loss: 0.0083\n",
      "Epoch 78/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.9961 - loss: 0.0317 - val_accuracy: 0.9966 - val_loss: 0.0111\n",
      "Epoch 79/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 365ms/step - accuracy: 0.9976 - loss: 0.0051 - val_accuracy: 0.9966 - val_loss: 0.0078\n",
      "Epoch 80/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.9973 - loss: 0.0120 - val_accuracy: 0.9939 - val_loss: 0.0156\n",
      "Epoch 81/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.9972 - loss: 0.0079 - val_accuracy: 0.9973 - val_loss: 0.0046\n",
      "Epoch 82/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.9983 - loss: 0.0058 - val_accuracy: 0.9852 - val_loss: 0.0608\n",
      "Epoch 83/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 356ms/step - accuracy: 0.9976 - loss: 0.0053 - val_accuracy: 0.9960 - val_loss: 0.0197\n",
      "Epoch 84/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.9962 - loss: 0.0145 - val_accuracy: 0.9953 - val_loss: 0.0101\n",
      "Epoch 85/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 362ms/step - accuracy: 0.9973 - loss: 0.0113 - val_accuracy: 0.9966 - val_loss: 0.0107\n",
      "Epoch 86/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 362ms/step - accuracy: 0.9980 - loss: 0.0065 - val_accuracy: 0.9953 - val_loss: 0.0204\n",
      "Epoch 87/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.9980 - loss: 0.0052 - val_accuracy: 0.9946 - val_loss: 0.0238\n",
      "Epoch 88/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.9970 - loss: 0.0123 - val_accuracy: 0.9933 - val_loss: 0.0234\n",
      "Epoch 89/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 355ms/step - accuracy: 0.9951 - loss: 0.0135 - val_accuracy: 0.9953 - val_loss: 0.0129\n",
      "Epoch 90/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.9975 - loss: 0.0098 - val_accuracy: 0.9960 - val_loss: 0.0139\n",
      "Epoch 91/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.9959 - loss: 0.0188 - val_accuracy: 0.9973 - val_loss: 0.0085\n",
      "Epoch 92/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 356ms/step - accuracy: 0.9988 - loss: 0.0040 - val_accuracy: 0.9980 - val_loss: 0.0050\n",
      "Epoch 93/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.9961 - loss: 0.0084 - val_accuracy: 0.9993 - val_loss: 0.0046\n",
      "Epoch 94/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.9966 - loss: 0.0092 - val_accuracy: 0.9953 - val_loss: 0.0166\n",
      "Epoch 95/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 365ms/step - accuracy: 0.9981 - loss: 0.0059 - val_accuracy: 0.9966 - val_loss: 0.0133\n",
      "Epoch 96/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 366ms/step - accuracy: 0.9981 - loss: 0.0034 - val_accuracy: 0.9966 - val_loss: 0.0107\n",
      "Epoch 97/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.9973 - loss: 0.0057 - val_accuracy: 0.9973 - val_loss: 0.0068\n",
      "Epoch 98/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 365ms/step - accuracy: 0.9983 - loss: 0.0036 - val_accuracy: 0.9987 - val_loss: 0.0036\n",
      "Epoch 99/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 368ms/step - accuracy: 0.9977 - loss: 0.0067 - val_accuracy: 0.9966 - val_loss: 0.0059\n",
      "Epoch 100/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.9982 - loss: 0.0070 - val_accuracy: 0.9993 - val_loss: 0.0037\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set paths to your dataset folders\n",
    "train_dir = '/home/esidserver/datasets/testing_cls/train/'\n",
    "val_dir = '/home/esidserver/datasets/testing_cls/val/'\n",
    "test_dir = '/home/esidserver/datasets/testing_cls/test/'\n",
    "\n",
    "# Image data generator with data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Data generator for validation and test\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Data loaders\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Important for confusion matrix\n",
    ")\n",
    "\n",
    "# Load the ResNet-50 model with pre-trained weights\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom top layers for classification\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping and model checkpoint\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('resnet50_best_model.keras', save_best_only=True, monitor='val_loss')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=250,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "\n",
    "# Fine-tuning: Unfreeze some layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compile the model again\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Continue training with fine-tuning\n",
    "history_finetune = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 104ms/step - accuracy: 0.9985 - loss: 0.0042\n",
      "Final Validation Accuracy: 0.9987, Validation Loss: 0.0036\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.9997 - loss: 0.0083"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 03:11:11.597212: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1719', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 288ms/step - accuracy: 0.9996 - loss: 0.0096\n",
      "Test Accuracy: 0.9986, Test Loss: 0.0245\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate on the validation set\n",
    "val_loss, val_acc = model.evaluate(val_generator)\n",
    "print(f\"Final Validation Accuracy: {val_acc:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Save the final model\n",
    "model.save('resnet50_final_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 259ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AB       1.00      1.00      1.00       188\n",
      "          AG       0.99      1.00      1.00       184\n",
      "         ANO       1.00      1.00      1.00       184\n",
      "          CQ       1.00      0.99      1.00       184\n",
      "\n",
      "    accuracy                           1.00       740\n",
      "   macro avg       1.00      1.00      1.00       740\n",
      "weighted avg       1.00      1.00      1.00       740\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for the test set\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Get true labels\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "cm_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=cm_labels, yticklabels=cm_labels)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report for precision, recall, f1-score\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred_classes, target_names=cm_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
