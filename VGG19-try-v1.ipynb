{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 11:33:11.173396: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-19 11:33:11.197754: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-19 11:33:11.230213: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-19 11:33:11.239034: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-19 11:33:11.261383: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-19 11:33:12.326262: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5193 images belonging to 4 classes.\n",
      "Found 1484 images belonging to 4 classes.\n",
      "Found 740 images belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 11:33:13.653619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22453 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:af:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/esidserver/miniforge3/envs/tf/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1726720400.945441 3678844 service.cc:146] XLA service 0x766f1c004e60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1726720400.945500 3678844 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-09-19 11:33:21.031957: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-09-19 11:33:21.402854: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8902\n",
      "2024-09-19 11:33:21.840954: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_944', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-09-19 11:33:22.662226: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1343', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-09-19 11:33:22.742852: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_944', 136 bytes spill stores, 136 bytes spill loads\n",
      "\n",
      "2024-09-19 11:33:22.829928: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1343', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2024-09-19 11:33:22.861162: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1343', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2024-09-19 11:33:23.011502: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1343', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/163\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m27:11\u001b[0m 10s/step - accuracy: 0.2500 - loss: 1.5517"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1726720406.297619 3678844 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 17/163\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m47s\u001b[0m 327ms/step - accuracy: 0.2103 - loss: 1.4494"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 11:33:33.617828: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_944', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - accuracy: 0.3909 - loss: 1.3202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 11:34:31.009978: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_252', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 416ms/step - accuracy: 0.3922 - loss: 1.3191 - val_accuracy: 0.6550 - val_loss: 1.0660\n",
      "Epoch 2/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.6162 - loss: 1.0644 - val_accuracy: 0.7177 - val_loss: 0.8977\n",
      "Epoch 3/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 355ms/step - accuracy: 0.6661 - loss: 0.9382 - val_accuracy: 0.7271 - val_loss: 0.7956\n",
      "Epoch 4/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 356ms/step - accuracy: 0.6910 - loss: 0.8459 - val_accuracy: 0.7540 - val_loss: 0.7144\n",
      "Epoch 5/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 367ms/step - accuracy: 0.7083 - loss: 0.7927 - val_accuracy: 0.7823 - val_loss: 0.6455\n",
      "Epoch 6/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 354ms/step - accuracy: 0.7262 - loss: 0.7470 - val_accuracy: 0.7823 - val_loss: 0.6265\n",
      "Epoch 7/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 354ms/step - accuracy: 0.7175 - loss: 0.7198 - val_accuracy: 0.7931 - val_loss: 0.5815\n",
      "Epoch 8/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 359ms/step - accuracy: 0.7299 - loss: 0.7026 - val_accuracy: 0.8093 - val_loss: 0.5375\n",
      "Epoch 9/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 359ms/step - accuracy: 0.7571 - loss: 0.6483 - val_accuracy: 0.8127 - val_loss: 0.5143\n",
      "Epoch 10/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.7697 - loss: 0.6180 - val_accuracy: 0.8174 - val_loss: 0.4928\n",
      "Epoch 11/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 355ms/step - accuracy: 0.7791 - loss: 0.5978 - val_accuracy: 0.8248 - val_loss: 0.4842\n",
      "Epoch 12/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 361ms/step - accuracy: 0.7705 - loss: 0.5960 - val_accuracy: 0.8302 - val_loss: 0.4690\n",
      "Epoch 13/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.7624 - loss: 0.5851 - val_accuracy: 0.8322 - val_loss: 0.4464\n",
      "Epoch 14/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.7882 - loss: 0.5610 - val_accuracy: 0.8389 - val_loss: 0.4340\n",
      "Epoch 15/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.7857 - loss: 0.5547 - val_accuracy: 0.8329 - val_loss: 0.4257\n",
      "Epoch 16/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.7936 - loss: 0.5268 - val_accuracy: 0.8430 - val_loss: 0.4173\n",
      "Epoch 17/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.8082 - loss: 0.5152 - val_accuracy: 0.8383 - val_loss: 0.4038\n",
      "Epoch 18/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.8111 - loss: 0.5108 - val_accuracy: 0.8464 - val_loss: 0.3976\n",
      "Epoch 19/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.8063 - loss: 0.4990 - val_accuracy: 0.8551 - val_loss: 0.3868\n",
      "Epoch 20/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.8197 - loss: 0.4838 - val_accuracy: 0.8484 - val_loss: 0.3909\n",
      "Epoch 21/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.8185 - loss: 0.4884 - val_accuracy: 0.8565 - val_loss: 0.3805\n",
      "Epoch 22/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 362ms/step - accuracy: 0.8166 - loss: 0.4787 - val_accuracy: 0.8592 - val_loss: 0.3687\n",
      "Epoch 23/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 365ms/step - accuracy: 0.8202 - loss: 0.4733 - val_accuracy: 0.8619 - val_loss: 0.3660\n",
      "Epoch 24/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 354ms/step - accuracy: 0.8312 - loss: 0.4494 - val_accuracy: 0.8518 - val_loss: 0.3753\n",
      "Epoch 25/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.8282 - loss: 0.4621 - val_accuracy: 0.8646 - val_loss: 0.3511\n",
      "Epoch 26/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 349ms/step - accuracy: 0.8216 - loss: 0.4519 - val_accuracy: 0.8605 - val_loss: 0.3547\n",
      "Epoch 27/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.8354 - loss: 0.4369 - val_accuracy: 0.8673 - val_loss: 0.3394\n",
      "Epoch 28/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 355ms/step - accuracy: 0.8281 - loss: 0.4373 - val_accuracy: 0.8632 - val_loss: 0.3505\n",
      "Epoch 29/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.8399 - loss: 0.4254 - val_accuracy: 0.8699 - val_loss: 0.3316\n",
      "Epoch 30/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 346ms/step - accuracy: 0.8348 - loss: 0.4165 - val_accuracy: 0.8706 - val_loss: 0.3314\n",
      "Epoch 31/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.8462 - loss: 0.4108 - val_accuracy: 0.8632 - val_loss: 0.3402\n",
      "Epoch 32/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.8397 - loss: 0.4161 - val_accuracy: 0.8686 - val_loss: 0.3276\n",
      "Epoch 33/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.8562 - loss: 0.3970 - val_accuracy: 0.8740 - val_loss: 0.3185\n",
      "Epoch 34/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 345ms/step - accuracy: 0.8528 - loss: 0.3927 - val_accuracy: 0.8625 - val_loss: 0.3411\n",
      "Epoch 35/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.8465 - loss: 0.3995 - val_accuracy: 0.8733 - val_loss: 0.3188\n",
      "Epoch 36/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.8447 - loss: 0.4060 - val_accuracy: 0.8760 - val_loss: 0.3065\n",
      "Epoch 37/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.8566 - loss: 0.3807 - val_accuracy: 0.8767 - val_loss: 0.3109\n",
      "Epoch 38/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 350ms/step - accuracy: 0.8594 - loss: 0.3830 - val_accuracy: 0.8713 - val_loss: 0.3173\n",
      "Epoch 39/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.8693 - loss: 0.3675 - val_accuracy: 0.8780 - val_loss: 0.3021\n",
      "Epoch 40/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 349ms/step - accuracy: 0.8361 - loss: 0.4035 - val_accuracy: 0.8760 - val_loss: 0.2965\n",
      "Epoch 41/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.8582 - loss: 0.3711 - val_accuracy: 0.8747 - val_loss: 0.3049\n",
      "Epoch 42/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.8551 - loss: 0.3791 - val_accuracy: 0.8767 - val_loss: 0.3026\n",
      "Epoch 43/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.8499 - loss: 0.3745 - val_accuracy: 0.8780 - val_loss: 0.3105\n",
      "Epoch 44/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.8565 - loss: 0.3646 - val_accuracy: 0.8801 - val_loss: 0.2997\n",
      "Epoch 45/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.8584 - loss: 0.3625 - val_accuracy: 0.8794 - val_loss: 0.2951\n",
      "Epoch 46/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 344ms/step - accuracy: 0.8522 - loss: 0.3793 - val_accuracy: 0.8807 - val_loss: 0.2835\n",
      "Epoch 47/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 344ms/step - accuracy: 0.8573 - loss: 0.3781 - val_accuracy: 0.8807 - val_loss: 0.2873\n",
      "Epoch 48/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 346ms/step - accuracy: 0.8647 - loss: 0.3593 - val_accuracy: 0.8827 - val_loss: 0.2796\n",
      "Epoch 49/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.8604 - loss: 0.3592 - val_accuracy: 0.8861 - val_loss: 0.2790\n",
      "Epoch 50/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 349ms/step - accuracy: 0.8615 - loss: 0.3653 - val_accuracy: 0.8794 - val_loss: 0.3016\n",
      "Epoch 51/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 344ms/step - accuracy: 0.8637 - loss: 0.3533 - val_accuracy: 0.8706 - val_loss: 0.3116\n",
      "Epoch 52/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.8639 - loss: 0.3504 - val_accuracy: 0.8774 - val_loss: 0.2824\n",
      "Epoch 53/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.8772 - loss: 0.3400 - val_accuracy: 0.8881 - val_loss: 0.2832\n",
      "Epoch 54/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.8626 - loss: 0.3545 - val_accuracy: 0.8827 - val_loss: 0.2882\n",
      "Epoch 55/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.8646 - loss: 0.3612 - val_accuracy: 0.8848 - val_loss: 0.2733\n",
      "Epoch 56/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 349ms/step - accuracy: 0.8673 - loss: 0.3489 - val_accuracy: 0.8922 - val_loss: 0.2765\n",
      "Epoch 57/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.8697 - loss: 0.3373 - val_accuracy: 0.8881 - val_loss: 0.2808\n",
      "Epoch 58/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.8690 - loss: 0.3409 - val_accuracy: 0.8935 - val_loss: 0.2715\n",
      "Epoch 59/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.8711 - loss: 0.3418 - val_accuracy: 0.8922 - val_loss: 0.2645\n",
      "Epoch 60/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.8767 - loss: 0.3273 - val_accuracy: 0.8767 - val_loss: 0.2875\n",
      "Epoch 61/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.8594 - loss: 0.3470 - val_accuracy: 0.8942 - val_loss: 0.2747\n",
      "Epoch 62/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.8635 - loss: 0.3430 - val_accuracy: 0.8949 - val_loss: 0.2597\n",
      "Epoch 63/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.8787 - loss: 0.3221 - val_accuracy: 0.8929 - val_loss: 0.2804\n",
      "Epoch 64/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 342ms/step - accuracy: 0.8634 - loss: 0.3348 - val_accuracy: 0.8929 - val_loss: 0.2719\n",
      "Epoch 65/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 346ms/step - accuracy: 0.8596 - loss: 0.3469 - val_accuracy: 0.8929 - val_loss: 0.2835\n",
      "Epoch 66/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 350ms/step - accuracy: 0.8672 - loss: 0.3386 - val_accuracy: 0.8929 - val_loss: 0.2640\n",
      "Epoch 67/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.8769 - loss: 0.3156 - val_accuracy: 0.9003 - val_loss: 0.2587\n",
      "Epoch 68/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.8735 - loss: 0.3230 - val_accuracy: 0.8915 - val_loss: 0.2662\n",
      "Epoch 69/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.8744 - loss: 0.3358 - val_accuracy: 0.8989 - val_loss: 0.2534\n",
      "Epoch 70/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 359ms/step - accuracy: 0.8760 - loss: 0.3258 - val_accuracy: 0.8976 - val_loss: 0.2518\n",
      "Epoch 71/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.8800 - loss: 0.3061 - val_accuracy: 0.8989 - val_loss: 0.2711\n",
      "Epoch 72/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.8736 - loss: 0.3267 - val_accuracy: 0.9023 - val_loss: 0.2551\n",
      "Epoch 73/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 348ms/step - accuracy: 0.8782 - loss: 0.3002 - val_accuracy: 0.9023 - val_loss: 0.2575\n",
      "Epoch 74/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.8847 - loss: 0.3016 - val_accuracy: 0.8962 - val_loss: 0.2631\n",
      "Epoch 75/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.8789 - loss: 0.3178 - val_accuracy: 0.8996 - val_loss: 0.2490\n",
      "Epoch 76/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 346ms/step - accuracy: 0.8802 - loss: 0.3224 - val_accuracy: 0.9003 - val_loss: 0.2507\n",
      "Epoch 77/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.8826 - loss: 0.3129 - val_accuracy: 0.8969 - val_loss: 0.2484\n",
      "Epoch 78/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.8850 - loss: 0.3048 - val_accuracy: 0.9016 - val_loss: 0.2598\n",
      "Epoch 79/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.8912 - loss: 0.2930 - val_accuracy: 0.8996 - val_loss: 0.2501\n",
      "Epoch 80/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 356ms/step - accuracy: 0.8775 - loss: 0.3146 - val_accuracy: 0.9023 - val_loss: 0.2413\n",
      "Epoch 81/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.8778 - loss: 0.3220 - val_accuracy: 0.8949 - val_loss: 0.2553\n",
      "Epoch 82/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 366ms/step - accuracy: 0.8751 - loss: 0.3197 - val_accuracy: 0.9050 - val_loss: 0.2447\n",
      "Epoch 83/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 356ms/step - accuracy: 0.8879 - loss: 0.3107 - val_accuracy: 0.9070 - val_loss: 0.2407\n",
      "Epoch 84/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.8877 - loss: 0.3005 - val_accuracy: 0.9030 - val_loss: 0.2404\n",
      "Epoch 85/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.8851 - loss: 0.3040 - val_accuracy: 0.8982 - val_loss: 0.2546\n",
      "Epoch 86/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.8717 - loss: 0.3188 - val_accuracy: 0.8969 - val_loss: 0.2490\n",
      "Epoch 87/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 346ms/step - accuracy: 0.8808 - loss: 0.3088 - val_accuracy: 0.9003 - val_loss: 0.2436\n",
      "Epoch 88/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.8754 - loss: 0.3006 - val_accuracy: 0.9043 - val_loss: 0.2350\n",
      "Epoch 89/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.8891 - loss: 0.2890 - val_accuracy: 0.9016 - val_loss: 0.2381\n",
      "Epoch 90/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.8915 - loss: 0.2900 - val_accuracy: 0.9036 - val_loss: 0.2404\n",
      "Epoch 91/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.8869 - loss: 0.3002 - val_accuracy: 0.8929 - val_loss: 0.2553\n",
      "Epoch 92/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.8824 - loss: 0.2981 - val_accuracy: 0.9057 - val_loss: 0.2305\n",
      "Epoch 93/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 346ms/step - accuracy: 0.8839 - loss: 0.3020 - val_accuracy: 0.9030 - val_loss: 0.2326\n",
      "Epoch 94/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.8892 - loss: 0.2864 - val_accuracy: 0.8996 - val_loss: 0.2610\n",
      "Epoch 95/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 344ms/step - accuracy: 0.8864 - loss: 0.2896 - val_accuracy: 0.9063 - val_loss: 0.2368\n",
      "Epoch 96/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 343ms/step - accuracy: 0.8867 - loss: 0.2952 - val_accuracy: 0.9050 - val_loss: 0.2481\n",
      "Epoch 97/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 346ms/step - accuracy: 0.8894 - loss: 0.2894 - val_accuracy: 0.9124 - val_loss: 0.2341\n",
      "Epoch 98/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 349ms/step - accuracy: 0.8859 - loss: 0.2938 - val_accuracy: 0.9090 - val_loss: 0.2342\n",
      "Epoch 99/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 349ms/step - accuracy: 0.8762 - loss: 0.3004 - val_accuracy: 0.9057 - val_loss: 0.2317\n",
      "Epoch 100/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 356ms/step - accuracy: 0.8971 - loss: 0.2780 - val_accuracy: 0.9084 - val_loss: 0.2278\n",
      "Epoch 101/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 343ms/step - accuracy: 0.8970 - loss: 0.2767 - val_accuracy: 0.9063 - val_loss: 0.2395\n",
      "Epoch 102/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.8907 - loss: 0.2908 - val_accuracy: 0.9097 - val_loss: 0.2241\n",
      "Epoch 103/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 346ms/step - accuracy: 0.8893 - loss: 0.2867 - val_accuracy: 0.9084 - val_loss: 0.2313\n",
      "Epoch 104/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.8910 - loss: 0.2924 - val_accuracy: 0.9057 - val_loss: 0.2240\n",
      "Epoch 105/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 355ms/step - accuracy: 0.8951 - loss: 0.2756 - val_accuracy: 0.9063 - val_loss: 0.2235\n",
      "Epoch 106/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 354ms/step - accuracy: 0.8927 - loss: 0.2853 - val_accuracy: 0.9050 - val_loss: 0.2348\n",
      "Epoch 107/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 355ms/step - accuracy: 0.8920 - loss: 0.2863 - val_accuracy: 0.9023 - val_loss: 0.2530\n",
      "Epoch 108/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.8921 - loss: 0.2812 - val_accuracy: 0.9084 - val_loss: 0.2252\n",
      "Epoch 109/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.9053 - loss: 0.2626 - val_accuracy: 0.9043 - val_loss: 0.2447\n",
      "Epoch 110/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 349ms/step - accuracy: 0.8838 - loss: 0.2995 - val_accuracy: 0.9036 - val_loss: 0.2310\n",
      "Epoch 111/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 346ms/step - accuracy: 0.8915 - loss: 0.2839 - val_accuracy: 0.9023 - val_loss: 0.2283\n",
      "Epoch 112/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.9007 - loss: 0.2644 - val_accuracy: 0.9043 - val_loss: 0.2285\n",
      "Epoch 113/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.8977 - loss: 0.2722 - val_accuracy: 0.9023 - val_loss: 0.2507\n",
      "Epoch 114/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.8812 - loss: 0.2922 - val_accuracy: 0.9104 - val_loss: 0.2193\n",
      "Epoch 115/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 354ms/step - accuracy: 0.8966 - loss: 0.2766 - val_accuracy: 0.9084 - val_loss: 0.2183\n",
      "Epoch 116/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.8939 - loss: 0.2778 - val_accuracy: 0.9050 - val_loss: 0.2307\n",
      "Epoch 117/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 349ms/step - accuracy: 0.9031 - loss: 0.2605 - val_accuracy: 0.9104 - val_loss: 0.2155\n",
      "Epoch 118/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.8929 - loss: 0.2784 - val_accuracy: 0.9131 - val_loss: 0.2220\n",
      "Epoch 119/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.8901 - loss: 0.2849 - val_accuracy: 0.9111 - val_loss: 0.2244\n",
      "Epoch 120/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.8937 - loss: 0.2746 - val_accuracy: 0.9084 - val_loss: 0.2205\n",
      "Epoch 121/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.8924 - loss: 0.2733 - val_accuracy: 0.9164 - val_loss: 0.2184\n",
      "Epoch 122/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.9018 - loss: 0.2580 - val_accuracy: 0.9131 - val_loss: 0.2169\n",
      "Epoch 123/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 346ms/step - accuracy: 0.8912 - loss: 0.2853 - val_accuracy: 0.9111 - val_loss: 0.2245\n",
      "Epoch 124/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 381ms/step - accuracy: 0.9028 - loss: 0.2627 - val_accuracy: 0.9104 - val_loss: 0.2223\n",
      "Epoch 125/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 399ms/step - accuracy: 0.8956 - loss: 0.2832 - val_accuracy: 0.9131 - val_loss: 0.2100\n",
      "Epoch 126/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 359ms/step - accuracy: 0.8861 - loss: 0.2814 - val_accuracy: 0.9164 - val_loss: 0.2058\n",
      "Epoch 127/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.9009 - loss: 0.2705 - val_accuracy: 0.9137 - val_loss: 0.2088\n",
      "Epoch 128/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 397ms/step - accuracy: 0.8900 - loss: 0.2617 - val_accuracy: 0.9178 - val_loss: 0.2147\n",
      "Epoch 129/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 366ms/step - accuracy: 0.8866 - loss: 0.2779 - val_accuracy: 0.9036 - val_loss: 0.2374\n",
      "Epoch 130/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 391ms/step - accuracy: 0.8980 - loss: 0.2650 - val_accuracy: 0.9097 - val_loss: 0.2174\n",
      "Epoch 131/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 388ms/step - accuracy: 0.9024 - loss: 0.2604 - val_accuracy: 0.9178 - val_loss: 0.2157\n",
      "Epoch 132/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 381ms/step - accuracy: 0.8975 - loss: 0.2576 - val_accuracy: 0.9171 - val_loss: 0.2167\n",
      "Epoch 133/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 412ms/step - accuracy: 0.8961 - loss: 0.2704 - val_accuracy: 0.9151 - val_loss: 0.2092\n",
      "Epoch 134/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 379ms/step - accuracy: 0.8884 - loss: 0.2711 - val_accuracy: 0.9131 - val_loss: 0.2121\n",
      "Epoch 135/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 368ms/step - accuracy: 0.8955 - loss: 0.2730 - val_accuracy: 0.9090 - val_loss: 0.2152\n",
      "Epoch 136/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 344ms/step - accuracy: 0.8962 - loss: 0.2625 - val_accuracy: 0.9084 - val_loss: 0.2345\n",
      "Epoch 137/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 346ms/step - accuracy: 0.9035 - loss: 0.2544 - val_accuracy: 0.9137 - val_loss: 0.2162\n",
      "Epoch 138/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 344ms/step - accuracy: 0.8986 - loss: 0.2602 - val_accuracy: 0.9117 - val_loss: 0.2164\n",
      "Epoch 139/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 380ms/step - accuracy: 0.9116 - loss: 0.2418 - val_accuracy: 0.9124 - val_loss: 0.2108\n",
      "Epoch 140/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 366ms/step - accuracy: 0.8937 - loss: 0.2670 - val_accuracy: 0.9131 - val_loss: 0.2085\n",
      "Epoch 141/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 366ms/step - accuracy: 0.9073 - loss: 0.2530 - val_accuracy: 0.9191 - val_loss: 0.2019\n",
      "Epoch 142/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.9039 - loss: 0.2507 - val_accuracy: 0.9218 - val_loss: 0.2010\n",
      "Epoch 143/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 359ms/step - accuracy: 0.8957 - loss: 0.2642 - val_accuracy: 0.9144 - val_loss: 0.2094\n",
      "Epoch 144/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.9175 - loss: 0.2288 - val_accuracy: 0.9171 - val_loss: 0.2021\n",
      "Epoch 145/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.9053 - loss: 0.2522 - val_accuracy: 0.9191 - val_loss: 0.1953\n",
      "Epoch 146/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 343ms/step - accuracy: 0.9069 - loss: 0.2570 - val_accuracy: 0.9212 - val_loss: 0.2034\n",
      "Epoch 147/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 344ms/step - accuracy: 0.8974 - loss: 0.2584 - val_accuracy: 0.9171 - val_loss: 0.2080\n",
      "Epoch 148/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 339ms/step - accuracy: 0.9035 - loss: 0.2530 - val_accuracy: 0.9191 - val_loss: 0.2067\n",
      "Epoch 149/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 349ms/step - accuracy: 0.8993 - loss: 0.2707 - val_accuracy: 0.9164 - val_loss: 0.2026\n",
      "Epoch 150/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 346ms/step - accuracy: 0.9071 - loss: 0.2482 - val_accuracy: 0.9171 - val_loss: 0.2011\n",
      "Epoch 151/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 344ms/step - accuracy: 0.9048 - loss: 0.2528 - val_accuracy: 0.9137 - val_loss: 0.2098\n",
      "Epoch 152/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.9048 - loss: 0.2493 - val_accuracy: 0.9191 - val_loss: 0.2034\n",
      "Epoch 153/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.9048 - loss: 0.2544 - val_accuracy: 0.9171 - val_loss: 0.2007\n",
      "Epoch 154/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.9070 - loss: 0.2484 - val_accuracy: 0.9137 - val_loss: 0.2121\n",
      "Epoch 155/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 343ms/step - accuracy: 0.9008 - loss: 0.2537 - val_accuracy: 0.9205 - val_loss: 0.1980\n",
      "Epoch 156/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 339ms/step - accuracy: 0.9147 - loss: 0.2254 - val_accuracy: 0.9198 - val_loss: 0.1981\n",
      "Epoch 157/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 345ms/step - accuracy: 0.9130 - loss: 0.2364 - val_accuracy: 0.9178 - val_loss: 0.1926\n",
      "Epoch 158/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 344ms/step - accuracy: 0.8989 - loss: 0.2524 - val_accuracy: 0.9151 - val_loss: 0.2020\n",
      "Epoch 159/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 349ms/step - accuracy: 0.9050 - loss: 0.2472 - val_accuracy: 0.9218 - val_loss: 0.2065\n",
      "Epoch 160/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 339ms/step - accuracy: 0.9099 - loss: 0.2543 - val_accuracy: 0.9185 - val_loss: 0.2013\n",
      "Epoch 161/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 342ms/step - accuracy: 0.9066 - loss: 0.2583 - val_accuracy: 0.9205 - val_loss: 0.1960\n",
      "Epoch 162/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 342ms/step - accuracy: 0.9060 - loss: 0.2517 - val_accuracy: 0.9178 - val_loss: 0.1962\n",
      "Epoch 163/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 340ms/step - accuracy: 0.9035 - loss: 0.2454 - val_accuracy: 0.9063 - val_loss: 0.2230\n",
      "Epoch 164/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 338ms/step - accuracy: 0.9065 - loss: 0.2357 - val_accuracy: 0.9178 - val_loss: 0.1971\n",
      "Epoch 165/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 339ms/step - accuracy: 0.9049 - loss: 0.2432 - val_accuracy: 0.9178 - val_loss: 0.1964\n",
      "Epoch 166/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 341ms/step - accuracy: 0.9047 - loss: 0.2478 - val_accuracy: 0.9111 - val_loss: 0.2135\n",
      "Epoch 167/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 344ms/step - accuracy: 0.9080 - loss: 0.2438 - val_accuracy: 0.9131 - val_loss: 0.2093\n",
      "Epoch 168/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.8973 - loss: 0.2577 - val_accuracy: 0.9164 - val_loss: 0.1921\n",
      "Epoch 169/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 338ms/step - accuracy: 0.9053 - loss: 0.2499 - val_accuracy: 0.9158 - val_loss: 0.2028\n",
      "Epoch 170/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 346ms/step - accuracy: 0.9076 - loss: 0.2525 - val_accuracy: 0.9205 - val_loss: 0.1874\n",
      "Epoch 171/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 342ms/step - accuracy: 0.9122 - loss: 0.2397 - val_accuracy: 0.9178 - val_loss: 0.1998\n",
      "Epoch 172/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 343ms/step - accuracy: 0.8996 - loss: 0.2518 - val_accuracy: 0.9225 - val_loss: 0.1915\n",
      "Epoch 173/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.9124 - loss: 0.2332 - val_accuracy: 0.9218 - val_loss: 0.1895\n",
      "Epoch 174/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.9075 - loss: 0.2531 - val_accuracy: 0.9144 - val_loss: 0.2019\n",
      "Epoch 175/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.9075 - loss: 0.2416 - val_accuracy: 0.9178 - val_loss: 0.1996\n",
      "Epoch 176/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.8998 - loss: 0.2478 - val_accuracy: 0.9151 - val_loss: 0.2064\n",
      "Epoch 177/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.9084 - loss: 0.2318 - val_accuracy: 0.9218 - val_loss: 0.1909\n",
      "Epoch 178/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.9096 - loss: 0.2344 - val_accuracy: 0.9232 - val_loss: 0.1995\n",
      "Epoch 179/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.9122 - loss: 0.2375 - val_accuracy: 0.9205 - val_loss: 0.1941\n",
      "Epoch 180/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.9050 - loss: 0.2542 - val_accuracy: 0.9245 - val_loss: 0.1969\n",
      "Epoch 181/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 349ms/step - accuracy: 0.9135 - loss: 0.2287 - val_accuracy: 0.9212 - val_loss: 0.1946\n",
      "Epoch 182/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 346ms/step - accuracy: 0.9048 - loss: 0.2445 - val_accuracy: 0.9245 - val_loss: 0.1913\n",
      "Epoch 183/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.9205 - loss: 0.2121 - val_accuracy: 0.9218 - val_loss: 0.1913\n",
      "Epoch 184/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 339ms/step - accuracy: 0.9016 - loss: 0.2384 - val_accuracy: 0.9252 - val_loss: 0.1908\n",
      "Epoch 185/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 342ms/step - accuracy: 0.9113 - loss: 0.2303 - val_accuracy: 0.9245 - val_loss: 0.1906\n",
      "Epoch 186/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 343ms/step - accuracy: 0.9203 - loss: 0.2333 - val_accuracy: 0.9225 - val_loss: 0.2018\n",
      "Epoch 187/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 344ms/step - accuracy: 0.9067 - loss: 0.2405 - val_accuracy: 0.9218 - val_loss: 0.1873\n",
      "Epoch 188/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 344ms/step - accuracy: 0.9140 - loss: 0.2289 - val_accuracy: 0.9191 - val_loss: 0.2008\n",
      "Epoch 189/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 343ms/step - accuracy: 0.9129 - loss: 0.2292 - val_accuracy: 0.9232 - val_loss: 0.1915\n",
      "Epoch 190/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.9113 - loss: 0.2316 - val_accuracy: 0.9245 - val_loss: 0.1833\n",
      "Epoch 191/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 345ms/step - accuracy: 0.9085 - loss: 0.2410 - val_accuracy: 0.9259 - val_loss: 0.1883\n",
      "Epoch 192/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.9153 - loss: 0.2217 - val_accuracy: 0.9272 - val_loss: 0.1859\n",
      "Epoch 193/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.9111 - loss: 0.2259 - val_accuracy: 0.9245 - val_loss: 0.1878\n",
      "Epoch 194/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 346ms/step - accuracy: 0.9098 - loss: 0.2294 - val_accuracy: 0.9232 - val_loss: 0.1867\n",
      "Epoch 195/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 344ms/step - accuracy: 0.9093 - loss: 0.2343 - val_accuracy: 0.9171 - val_loss: 0.1939\n",
      "Epoch 196/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 343ms/step - accuracy: 0.9033 - loss: 0.2362 - val_accuracy: 0.9265 - val_loss: 0.1842\n",
      "Epoch 197/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 345ms/step - accuracy: 0.9040 - loss: 0.2449 - val_accuracy: 0.9306 - val_loss: 0.1822\n",
      "Epoch 198/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 343ms/step - accuracy: 0.9183 - loss: 0.2269 - val_accuracy: 0.9198 - val_loss: 0.2011\n",
      "Epoch 199/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.9072 - loss: 0.2351 - val_accuracy: 0.9259 - val_loss: 0.1793\n",
      "Epoch 200/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.9200 - loss: 0.2168 - val_accuracy: 0.9299 - val_loss: 0.1837\n",
      "Epoch 201/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 349ms/step - accuracy: 0.9174 - loss: 0.2140 - val_accuracy: 0.9265 - val_loss: 0.1890\n",
      "Epoch 202/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 348ms/step - accuracy: 0.9166 - loss: 0.2245 - val_accuracy: 0.9245 - val_loss: 0.1947\n",
      "Epoch 203/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.9119 - loss: 0.2321 - val_accuracy: 0.9259 - val_loss: 0.1786\n",
      "Epoch 204/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 349ms/step - accuracy: 0.9066 - loss: 0.2355 - val_accuracy: 0.9097 - val_loss: 0.2173\n",
      "Epoch 205/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.9233 - loss: 0.2217 - val_accuracy: 0.9286 - val_loss: 0.1727\n",
      "Epoch 206/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 362ms/step - accuracy: 0.9178 - loss: 0.2309 - val_accuracy: 0.9218 - val_loss: 0.1846\n",
      "Epoch 207/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 359ms/step - accuracy: 0.9141 - loss: 0.2339 - val_accuracy: 0.9313 - val_loss: 0.1776\n",
      "Epoch 208/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 355ms/step - accuracy: 0.9187 - loss: 0.2186 - val_accuracy: 0.9239 - val_loss: 0.2003\n",
      "Epoch 209/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 359ms/step - accuracy: 0.9170 - loss: 0.2202 - val_accuracy: 0.9245 - val_loss: 0.1899\n",
      "Epoch 210/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 369ms/step - accuracy: 0.9082 - loss: 0.2345 - val_accuracy: 0.9265 - val_loss: 0.1818\n",
      "Epoch 211/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 344ms/step - accuracy: 0.9142 - loss: 0.2298 - val_accuracy: 0.9286 - val_loss: 0.1744\n",
      "Epoch 212/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.9166 - loss: 0.2334 - val_accuracy: 0.9104 - val_loss: 0.2163\n",
      "Epoch 213/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 344ms/step - accuracy: 0.9170 - loss: 0.2253 - val_accuracy: 0.9286 - val_loss: 0.1750\n",
      "Epoch 214/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.9180 - loss: 0.2058 - val_accuracy: 0.9299 - val_loss: 0.1709\n",
      "Epoch 215/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 345ms/step - accuracy: 0.9109 - loss: 0.2234 - val_accuracy: 0.9313 - val_loss: 0.1711\n",
      "Epoch 216/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.9128 - loss: 0.2275 - val_accuracy: 0.9313 - val_loss: 0.1684\n",
      "Epoch 217/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 346ms/step - accuracy: 0.9097 - loss: 0.2301 - val_accuracy: 0.9299 - val_loss: 0.1715\n",
      "Epoch 218/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.9274 - loss: 0.1883 - val_accuracy: 0.9279 - val_loss: 0.1776\n",
      "Epoch 219/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 346ms/step - accuracy: 0.9175 - loss: 0.2115 - val_accuracy: 0.9313 - val_loss: 0.1788\n",
      "Epoch 220/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 341ms/step - accuracy: 0.9171 - loss: 0.2277 - val_accuracy: 0.9239 - val_loss: 0.1790\n",
      "Epoch 221/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 342ms/step - accuracy: 0.9118 - loss: 0.2334 - val_accuracy: 0.9313 - val_loss: 0.1705\n",
      "Epoch 222/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.9133 - loss: 0.2271 - val_accuracy: 0.9319 - val_loss: 0.1670\n",
      "Epoch 223/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 349ms/step - accuracy: 0.9200 - loss: 0.2219 - val_accuracy: 0.9319 - val_loss: 0.1634\n",
      "Epoch 224/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 338ms/step - accuracy: 0.9151 - loss: 0.2156 - val_accuracy: 0.9319 - val_loss: 0.1701\n",
      "Epoch 225/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 343ms/step - accuracy: 0.9192 - loss: 0.2066 - val_accuracy: 0.9272 - val_loss: 0.1828\n",
      "Epoch 226/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.9168 - loss: 0.2179 - val_accuracy: 0.9306 - val_loss: 0.1790\n",
      "Epoch 227/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 343ms/step - accuracy: 0.9163 - loss: 0.2155 - val_accuracy: 0.9313 - val_loss: 0.1694\n",
      "Epoch 228/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 355ms/step - accuracy: 0.9120 - loss: 0.2163 - val_accuracy: 0.9259 - val_loss: 0.1864\n",
      "Epoch 229/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.9214 - loss: 0.2133 - val_accuracy: 0.9259 - val_loss: 0.1746\n",
      "Epoch 230/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.9240 - loss: 0.2049 - val_accuracy: 0.9340 - val_loss: 0.1649\n",
      "Epoch 231/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.9231 - loss: 0.2041 - val_accuracy: 0.9299 - val_loss: 0.1814\n",
      "Epoch 232/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.9217 - loss: 0.2086 - val_accuracy: 0.9333 - val_loss: 0.1657\n",
      "Epoch 233/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 345ms/step - accuracy: 0.9259 - loss: 0.2081 - val_accuracy: 0.9279 - val_loss: 0.1708\n",
      "Epoch 234/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 345ms/step - accuracy: 0.9175 - loss: 0.2170 - val_accuracy: 0.9326 - val_loss: 0.1659\n",
      "Epoch 235/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 346ms/step - accuracy: 0.9234 - loss: 0.2135 - val_accuracy: 0.9346 - val_loss: 0.1736\n",
      "Epoch 236/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.9239 - loss: 0.2046 - val_accuracy: 0.9326 - val_loss: 0.1619\n",
      "Epoch 237/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 344ms/step - accuracy: 0.9208 - loss: 0.2084 - val_accuracy: 0.9340 - val_loss: 0.1623\n",
      "Epoch 238/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.9315 - loss: 0.1899 - val_accuracy: 0.9326 - val_loss: 0.1681\n",
      "Epoch 239/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.9294 - loss: 0.2044 - val_accuracy: 0.9239 - val_loss: 0.1848\n",
      "Epoch 240/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.9201 - loss: 0.2169 - val_accuracy: 0.9340 - val_loss: 0.1704\n",
      "Epoch 241/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 343ms/step - accuracy: 0.9228 - loss: 0.2099 - val_accuracy: 0.9306 - val_loss: 0.1706\n",
      "Epoch 242/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.9274 - loss: 0.2021 - val_accuracy: 0.9326 - val_loss: 0.1698\n",
      "Epoch 243/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 349ms/step - accuracy: 0.9200 - loss: 0.2077 - val_accuracy: 0.9306 - val_loss: 0.1793\n",
      "Epoch 244/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 346ms/step - accuracy: 0.9182 - loss: 0.2202 - val_accuracy: 0.9259 - val_loss: 0.1904\n",
      "Epoch 245/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.9213 - loss: 0.2077 - val_accuracy: 0.9286 - val_loss: 0.1817\n",
      "Epoch 246/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 342ms/step - accuracy: 0.9128 - loss: 0.2144 - val_accuracy: 0.9292 - val_loss: 0.1720\n",
      "Epoch 247/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 346ms/step - accuracy: 0.9203 - loss: 0.2072 - val_accuracy: 0.9326 - val_loss: 0.1703\n",
      "Epoch 248/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 340ms/step - accuracy: 0.9266 - loss: 0.2057 - val_accuracy: 0.9313 - val_loss: 0.1674\n",
      "Epoch 249/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.9154 - loss: 0.2064 - val_accuracy: 0.9299 - val_loss: 0.1659\n",
      "Epoch 250/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 343ms/step - accuracy: 0.9269 - loss: 0.1975 - val_accuracy: 0.9306 - val_loss: 0.1733\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Set paths to your dataset folders\n",
    "train_dir = '/home/esidserver/datasets/testing_cls/train/'\n",
    "val_dir = '/home/esidserver/datasets/testing_cls/val/'\n",
    "test_dir = '/home/esidserver/datasets/testing_cls/test/'\n",
    "\n",
    "# Image data generator with data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Data generator for validation and test\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Data loaders\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Load the VGG19 model with pre-trained weights\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom top layers for classification\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping and model checkpoint\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('vgg19_best_model.keras', save_best_only=True, monitor='val_loss')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=250,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 15:43:00.786545: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1654', 76 bytes spill stores, 76 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 421ms/step - accuracy: 0.8838 - loss: 0.3063 - val_accuracy: 0.9340 - val_loss: 0.1700\n",
      "Epoch 2/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.9391 - loss: 0.1726 - val_accuracy: 0.9609 - val_loss: 0.1001\n",
      "Epoch 3/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 349ms/step - accuracy: 0.9587 - loss: 0.1150 - val_accuracy: 0.9677 - val_loss: 0.0837\n",
      "Epoch 4/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.9618 - loss: 0.1045 - val_accuracy: 0.9764 - val_loss: 0.0617\n",
      "Epoch 5/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.9685 - loss: 0.0781 - val_accuracy: 0.9818 - val_loss: 0.0452\n",
      "Epoch 6/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.9715 - loss: 0.0739 - val_accuracy: 0.9825 - val_loss: 0.0516\n",
      "Epoch 7/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.9820 - loss: 0.0497 - val_accuracy: 0.9818 - val_loss: 0.0464\n",
      "Epoch 8/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.9844 - loss: 0.0452 - val_accuracy: 0.9899 - val_loss: 0.0420\n",
      "Epoch 9/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.9804 - loss: 0.0567 - val_accuracy: 0.9825 - val_loss: 0.0508\n",
      "Epoch 10/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.9829 - loss: 0.0489 - val_accuracy: 0.9899 - val_loss: 0.0293\n",
      "Epoch 11/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.9864 - loss: 0.0411 - val_accuracy: 0.9865 - val_loss: 0.0368\n",
      "Epoch 12/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.9859 - loss: 0.0389 - val_accuracy: 0.9966 - val_loss: 0.0103\n",
      "Epoch 13/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 342ms/step - accuracy: 0.9874 - loss: 0.0314 - val_accuracy: 0.9906 - val_loss: 0.0318\n",
      "Epoch 14/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.9921 - loss: 0.0302 - val_accuracy: 0.9933 - val_loss: 0.0201\n",
      "Epoch 15/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.9906 - loss: 0.0294 - val_accuracy: 0.9912 - val_loss: 0.0276\n",
      "Epoch 16/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.9906 - loss: 0.0230 - val_accuracy: 0.9919 - val_loss: 0.0253\n",
      "Epoch 17/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 345ms/step - accuracy: 0.9879 - loss: 0.0348 - val_accuracy: 0.9885 - val_loss: 0.0278\n",
      "Epoch 18/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 349ms/step - accuracy: 0.9924 - loss: 0.0193 - val_accuracy: 0.9933 - val_loss: 0.0252\n",
      "Epoch 19/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 354ms/step - accuracy: 0.9918 - loss: 0.0248 - val_accuracy: 0.9960 - val_loss: 0.0154\n",
      "Epoch 20/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.9920 - loss: 0.0230 - val_accuracy: 0.9939 - val_loss: 0.0156\n",
      "Epoch 21/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.9854 - loss: 0.0382 - val_accuracy: 0.9899 - val_loss: 0.0245\n",
      "Epoch 22/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 345ms/step - accuracy: 0.9955 - loss: 0.0163 - val_accuracy: 0.9926 - val_loss: 0.0188\n",
      "Epoch 23/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 374ms/step - accuracy: 0.9914 - loss: 0.0243 - val_accuracy: 0.9953 - val_loss: 0.0173\n",
      "Epoch 24/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 371ms/step - accuracy: 0.9898 - loss: 0.0242 - val_accuracy: 0.9946 - val_loss: 0.0138\n",
      "Epoch 25/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 367ms/step - accuracy: 0.9932 - loss: 0.0227 - val_accuracy: 0.9933 - val_loss: 0.0207\n",
      "Epoch 26/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 359ms/step - accuracy: 0.9953 - loss: 0.0166 - val_accuracy: 0.9832 - val_loss: 0.0491\n",
      "Epoch 27/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 365ms/step - accuracy: 0.9849 - loss: 0.0380 - val_accuracy: 0.9872 - val_loss: 0.0439\n",
      "Epoch 28/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 365ms/step - accuracy: 0.9911 - loss: 0.0212 - val_accuracy: 0.9919 - val_loss: 0.0311\n",
      "Epoch 29/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 347ms/step - accuracy: 0.9933 - loss: 0.0184 - val_accuracy: 0.9892 - val_loss: 0.0341\n",
      "Epoch 30/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.9947 - loss: 0.0125 - val_accuracy: 0.9872 - val_loss: 0.0284\n",
      "Epoch 31/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.9887 - loss: 0.0360 - val_accuracy: 0.9892 - val_loss: 0.0333\n",
      "Epoch 32/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 342ms/step - accuracy: 0.9954 - loss: 0.0135 - val_accuracy: 0.9919 - val_loss: 0.0317\n",
      "Epoch 33/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 343ms/step - accuracy: 0.9914 - loss: 0.0270 - val_accuracy: 0.9946 - val_loss: 0.0201\n",
      "Epoch 34/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.9974 - loss: 0.0084 - val_accuracy: 0.9993 - val_loss: 0.0059\n",
      "Epoch 35/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 372ms/step - accuracy: 0.9974 - loss: 0.0104 - val_accuracy: 0.9926 - val_loss: 0.0230\n",
      "Epoch 36/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 387ms/step - accuracy: 0.9922 - loss: 0.0201 - val_accuracy: 0.9973 - val_loss: 0.0108\n",
      "Epoch 37/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.9917 - loss: 0.0176 - val_accuracy: 0.9919 - val_loss: 0.0187\n",
      "Epoch 38/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 365ms/step - accuracy: 0.9975 - loss: 0.0071 - val_accuracy: 0.9919 - val_loss: 0.0217\n",
      "Epoch 39/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 366ms/step - accuracy: 0.9957 - loss: 0.0134 - val_accuracy: 0.9933 - val_loss: 0.0177\n",
      "Epoch 40/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 370ms/step - accuracy: 0.9928 - loss: 0.0183 - val_accuracy: 0.9939 - val_loss: 0.0196\n",
      "Epoch 41/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 366ms/step - accuracy: 0.9872 - loss: 0.0277 - val_accuracy: 0.9879 - val_loss: 0.0467\n",
      "Epoch 42/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 369ms/step - accuracy: 0.9969 - loss: 0.0082 - val_accuracy: 0.9946 - val_loss: 0.0179\n",
      "Epoch 43/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.9938 - loss: 0.0182 - val_accuracy: 0.9865 - val_loss: 0.0526\n",
      "Epoch 44/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 350ms/step - accuracy: 0.9897 - loss: 0.0261 - val_accuracy: 0.9926 - val_loss: 0.0311\n",
      "Epoch 45/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 343ms/step - accuracy: 0.9908 - loss: 0.0199 - val_accuracy: 0.9933 - val_loss: 0.0137\n",
      "Epoch 46/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.9950 - loss: 0.0204 - val_accuracy: 0.9919 - val_loss: 0.0176\n",
      "Epoch 47/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.9981 - loss: 0.0069 - val_accuracy: 0.9933 - val_loss: 0.0191\n",
      "Epoch 48/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.9969 - loss: 0.0093 - val_accuracy: 0.9939 - val_loss: 0.0249\n",
      "Epoch 49/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.9973 - loss: 0.0077 - val_accuracy: 0.9987 - val_loss: 0.0056\n",
      "Epoch 50/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.9987 - loss: 0.0055 - val_accuracy: 0.9960 - val_loss: 0.0124\n",
      "Epoch 51/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.9973 - loss: 0.0074 - val_accuracy: 0.9953 - val_loss: 0.0118\n",
      "Epoch 52/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.9899 - loss: 0.0328 - val_accuracy: 0.9926 - val_loss: 0.0193\n",
      "Epoch 53/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.9948 - loss: 0.0183 - val_accuracy: 0.9980 - val_loss: 0.0057\n",
      "Epoch 54/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.9978 - loss: 0.0069 - val_accuracy: 0.9946 - val_loss: 0.0174\n",
      "Epoch 55/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 368ms/step - accuracy: 0.9966 - loss: 0.0089 - val_accuracy: 0.9926 - val_loss: 0.0233\n",
      "Epoch 56/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 369ms/step - accuracy: 0.9951 - loss: 0.0147 - val_accuracy: 0.9872 - val_loss: 0.0289\n",
      "Epoch 57/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.9919 - loss: 0.0191 - val_accuracy: 0.9791 - val_loss: 0.0694\n",
      "Epoch 58/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 344ms/step - accuracy: 0.9939 - loss: 0.0178 - val_accuracy: 0.9946 - val_loss: 0.0175\n",
      "Epoch 59/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 349ms/step - accuracy: 0.9938 - loss: 0.0147 - val_accuracy: 0.9912 - val_loss: 0.0258\n",
      "Epoch 60/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.9957 - loss: 0.0125 - val_accuracy: 0.9973 - val_loss: 0.0078\n",
      "Epoch 61/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 345ms/step - accuracy: 0.9980 - loss: 0.0063 - val_accuracy: 0.9892 - val_loss: 0.0221\n",
      "Epoch 62/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 344ms/step - accuracy: 0.9949 - loss: 0.0165 - val_accuracy: 0.9939 - val_loss: 0.0155\n",
      "Epoch 63/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 343ms/step - accuracy: 0.9968 - loss: 0.0119 - val_accuracy: 0.9946 - val_loss: 0.0190\n",
      "Epoch 64/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 345ms/step - accuracy: 0.9983 - loss: 0.0072 - val_accuracy: 0.9966 - val_loss: 0.0103\n",
      "Epoch 65/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 361ms/step - accuracy: 0.9956 - loss: 0.0117 - val_accuracy: 0.9933 - val_loss: 0.0184\n",
      "Epoch 66/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 378ms/step - accuracy: 0.9958 - loss: 0.0113 - val_accuracy: 0.9973 - val_loss: 0.0064\n",
      "Epoch 67/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 362ms/step - accuracy: 0.9974 - loss: 0.0064 - val_accuracy: 0.9623 - val_loss: 0.1169\n",
      "Epoch 68/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 365ms/step - accuracy: 0.9898 - loss: 0.0255 - val_accuracy: 0.9939 - val_loss: 0.0118\n",
      "Epoch 69/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 373ms/step - accuracy: 0.9983 - loss: 0.0049 - val_accuracy: 0.9987 - val_loss: 0.0075\n",
      "Epoch 70/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 362ms/step - accuracy: 0.9950 - loss: 0.0146 - val_accuracy: 0.9933 - val_loss: 0.0143\n",
      "Epoch 71/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 365ms/step - accuracy: 0.9972 - loss: 0.0081 - val_accuracy: 0.9973 - val_loss: 0.0053\n",
      "Epoch 72/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 343ms/step - accuracy: 0.9971 - loss: 0.0089 - val_accuracy: 0.9966 - val_loss: 0.0072\n",
      "Epoch 73/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.9979 - loss: 0.0070 - val_accuracy: 0.9899 - val_loss: 0.0361\n",
      "Epoch 74/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 346ms/step - accuracy: 0.9981 - loss: 0.0052 - val_accuracy: 0.9939 - val_loss: 0.0310\n",
      "Epoch 75/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 339ms/step - accuracy: 0.9960 - loss: 0.0094 - val_accuracy: 0.9852 - val_loss: 0.0591\n",
      "Epoch 76/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.9964 - loss: 0.0079 - val_accuracy: 0.9865 - val_loss: 0.0502\n",
      "Epoch 77/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 349ms/step - accuracy: 0.9962 - loss: 0.0089 - val_accuracy: 0.9960 - val_loss: 0.0109\n",
      "Epoch 78/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 346ms/step - accuracy: 0.9984 - loss: 0.0055 - val_accuracy: 0.9919 - val_loss: 0.0228\n",
      "Epoch 79/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.9980 - loss: 0.0068 - val_accuracy: 0.9946 - val_loss: 0.0247\n",
      "Epoch 80/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 346ms/step - accuracy: 0.9954 - loss: 0.0106 - val_accuracy: 0.9933 - val_loss: 0.0142\n",
      "Epoch 81/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 346ms/step - accuracy: 0.9947 - loss: 0.0126 - val_accuracy: 0.9946 - val_loss: 0.0231\n",
      "Epoch 82/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 343ms/step - accuracy: 0.9973 - loss: 0.0086 - val_accuracy: 0.9872 - val_loss: 0.0591\n",
      "Epoch 83/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 349ms/step - accuracy: 0.9952 - loss: 0.0145 - val_accuracy: 0.9845 - val_loss: 0.0511\n",
      "Epoch 84/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.9967 - loss: 0.0076 - val_accuracy: 0.9973 - val_loss: 0.0084\n",
      "Epoch 85/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 370ms/step - accuracy: 0.9974 - loss: 0.0085 - val_accuracy: 0.9953 - val_loss: 0.0073\n",
      "Epoch 86/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 369ms/step - accuracy: 0.9953 - loss: 0.0134 - val_accuracy: 0.9973 - val_loss: 0.0080\n",
      "Epoch 87/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 365ms/step - accuracy: 0.9981 - loss: 0.0055 - val_accuracy: 0.9946 - val_loss: 0.0200\n",
      "Epoch 88/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 376ms/step - accuracy: 0.9990 - loss: 0.0050 - val_accuracy: 0.9993 - val_loss: 0.0044\n",
      "Epoch 89/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 377ms/step - accuracy: 0.9980 - loss: 0.0065 - val_accuracy: 0.9987 - val_loss: 0.0036\n",
      "Epoch 90/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.9963 - loss: 0.0115 - val_accuracy: 0.9960 - val_loss: 0.0139\n",
      "Epoch 91/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 354ms/step - accuracy: 0.9948 - loss: 0.0130 - val_accuracy: 0.9933 - val_loss: 0.0238\n",
      "Epoch 92/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 342ms/step - accuracy: 0.9927 - loss: 0.0245 - val_accuracy: 0.9946 - val_loss: 0.0122\n",
      "Epoch 93/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 342ms/step - accuracy: 0.9970 - loss: 0.0087 - val_accuracy: 0.9966 - val_loss: 0.0061\n",
      "Epoch 94/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 346ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 0.9953 - val_loss: 0.0126\n",
      "Epoch 95/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 346ms/step - accuracy: 0.9977 - loss: 0.0062 - val_accuracy: 0.9980 - val_loss: 0.0044\n",
      "Epoch 96/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 341ms/step - accuracy: 0.9955 - loss: 0.0104 - val_accuracy: 0.9946 - val_loss: 0.0117\n",
      "Epoch 97/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 343ms/step - accuracy: 0.9982 - loss: 0.0045 - val_accuracy: 0.9926 - val_loss: 0.0250\n",
      "Epoch 98/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 349ms/step - accuracy: 0.9941 - loss: 0.0123 - val_accuracy: 0.9953 - val_loss: 0.0108\n",
      "Epoch 99/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.9975 - loss: 0.0073 - val_accuracy: 0.9939 - val_loss: 0.0166\n",
      "Epoch 100/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 349ms/step - accuracy: 0.9961 - loss: 0.0127 - val_accuracy: 0.9939 - val_loss: 0.0166\n"
     ]
    }
   ],
   "source": [
    "# Fine-tuning: Unfreeze some layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compile the model again\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Continue training with fine-tuning for 100 epochs\n",
    "history_finetune = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,  # Fine-tuning for 100 epochs\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.9957 - loss: 0.0209"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 17:24:07.577769: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_252', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 211ms/step - accuracy: 0.9957 - loss: 0.0208\n",
      "Final Training Accuracy: 0.9952\n",
      "Final Validation Accuracy: 0.9939\n",
      "Test Accuracy: 0.9959, Test Loss: 0.0196\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the test set\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "\n",
    "# Calculate final training and validation accuracy\n",
    "train_acc = history_finetune.history['accuracy'][-1] if 'accuracy' in history_finetune.history else None\n",
    "val_acc = history_finetune.history['val_accuracy'][-1] if 'val_accuracy' in history_finetune.history else None\n",
    "\n",
    "# Print the results\n",
    "print(f\"Final Training Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {val_acc:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Save the final model\n",
    "model.save('vgg19_final_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5193 images belonging to 4 classes.\n",
      "Found 1484 images belonging to 4 classes.\n",
      "Found 740 images belonging to 4 classes.\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/esidserver/miniforge3/envs/tf/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 372ms/step - accuracy: 0.4363 - loss: 1.2814 - val_accuracy: 0.6530 - val_loss: 1.0325\n",
      "Epoch 2/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 349ms/step - accuracy: 0.6247 - loss: 1.0482 - val_accuracy: 0.7049 - val_loss: 0.8784\n",
      "Epoch 3/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.6708 - loss: 0.9308 - val_accuracy: 0.7278 - val_loss: 0.7738\n",
      "Epoch 4/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 343ms/step - accuracy: 0.6980 - loss: 0.8180 - val_accuracy: 0.7446 - val_loss: 0.7124\n",
      "Epoch 5/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 345ms/step - accuracy: 0.7237 - loss: 0.7651 - val_accuracy: 0.7796 - val_loss: 0.6381\n",
      "Epoch 6/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 342ms/step - accuracy: 0.7461 - loss: 0.7092 - val_accuracy: 0.7911 - val_loss: 0.5891\n",
      "Epoch 7/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 342ms/step - accuracy: 0.7464 - loss: 0.6934 - val_accuracy: 0.7999 - val_loss: 0.5528\n",
      "Epoch 8/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 342ms/step - accuracy: 0.7603 - loss: 0.6441 - val_accuracy: 0.8019 - val_loss: 0.5340\n",
      "Epoch 9/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 345ms/step - accuracy: 0.7439 - loss: 0.6506 - val_accuracy: 0.8120 - val_loss: 0.5192\n",
      "Epoch 10/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 343ms/step - accuracy: 0.7771 - loss: 0.5902 - val_accuracy: 0.8214 - val_loss: 0.4907\n",
      "Epoch 11/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 344ms/step - accuracy: 0.7798 - loss: 0.5837 - val_accuracy: 0.8194 - val_loss: 0.4828\n",
      "Epoch 12/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 345ms/step - accuracy: 0.7922 - loss: 0.5539 - val_accuracy: 0.8127 - val_loss: 0.4761\n",
      "Epoch 13/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 342ms/step - accuracy: 0.7880 - loss: 0.5491 - val_accuracy: 0.8342 - val_loss: 0.4515\n",
      "Epoch 14/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 338ms/step - accuracy: 0.7893 - loss: 0.5432 - val_accuracy: 0.8363 - val_loss: 0.4286\n",
      "Epoch 15/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 341ms/step - accuracy: 0.8072 - loss: 0.5061 - val_accuracy: 0.8363 - val_loss: 0.4355\n",
      "Epoch 16/250\n",
      "\u001b[1m 59/163\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 387ms/step - accuracy: 0.8115 - loss: 0.5054"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 79\u001b[0m\n\u001b[1;32m     76\u001b[0m model_checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvgg19_best_model.keras\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set paths to your dataset folders\n",
    "train_dir = '/home/esidserver/datasets/testing_cls/training-v2/train/'\n",
    "val_dir = '/home/esidserver/datasets/testing_cls/training-v2/val/'\n",
    "test_dir = '/home/esidserver/datasets/testing_cls/training-v2/test/'\n",
    "\n",
    "# Image data generator with data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Data generator for validation and test\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Data loaders\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Important for confusion matrix to align predictions with true labels\n",
    ")\n",
    "\n",
    "# Load the VGG19 model with pre-trained weights\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom top layers for classification\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping and model checkpoint\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('vgg19_best_model.keras', save_best_only=True, monitor='val_loss')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=250,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning: Unfreeze some layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compile the model again\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Continue training with fine-tuning for 100 epochs\n",
    "history_finetune = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,  # Fine-tuning for 100 epochs\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test set\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "\n",
    "# Calculate final training and validation accuracy\n",
    "train_acc = history_finetune.history['accuracy'][-1] if 'accuracy' in history_finetune.history else None\n",
    "val_acc = history_finetune.history['val_accuracy'][-1] if 'val_accuracy' in history_finetune.history else None\n",
    "\n",
    "# Print the results\n",
    "print(f\"Final Training Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {val_acc:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Save the final model\n",
    "model.save('vgg19_final_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate predictions for the test set\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Get true labels\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "cm_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=cm_labels)\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
