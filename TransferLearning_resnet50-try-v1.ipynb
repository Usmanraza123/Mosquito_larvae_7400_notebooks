{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 16:43:38.790319: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-18 16:43:38.815134: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-18 16:43:38.861896: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-18 16:43:38.870537: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-18 16:43:38.902148: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-18 16:43:40.023387: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5193 images belonging to 4 classes.\n",
      "Found 1484 images belonging to 4 classes.\n",
      "Found 740 images belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 16:43:42.052506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22453 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:af:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/esidserver/miniforge3/envs/tf/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1726652635.220933 2014790 service.cc:146] XLA service 0x78fdac04b9f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1726652635.220989 2014790 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-09-18 16:43:55.568468: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-09-18 16:43:56.871623: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8902\n",
      "2024-09-18 16:43:58.004901: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5687', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-09-18 16:43:58.227407: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5887', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-09-18 16:43:58.438852: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5887', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2024-09-18 16:43:58.586636: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5887', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2024-09-18 16:43:58.720760: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5680', 176 bytes spill stores, 468 bytes spill loads\n",
      "\n",
      "2024-09-18 16:43:58.732848: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5887', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2024-09-18 16:43:58.847451: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5687', 136 bytes spill stores, 136 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/163\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m45:30\u001b[0m 17s/step - accuracy: 0.1875 - loss: 1.5210"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1726652642.385309 2014790 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m116/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 384ms/step - accuracy: 0.2679 - loss: 1.3976"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 16:44:49.522516: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5687', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - accuracy: 0.2746 - loss: 1.3916"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 16:45:19.703685: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1719', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 506ms/step - accuracy: 0.2750 - loss: 1.3914 - val_accuracy: 0.4319 - val_loss: 1.3234\n",
      "Epoch 2/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 393ms/step - accuracy: 0.3829 - loss: 1.3283 - val_accuracy: 0.4663 - val_loss: 1.2660\n",
      "Epoch 3/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 398ms/step - accuracy: 0.4122 - loss: 1.2869 - val_accuracy: 0.4299 - val_loss: 1.2575\n",
      "Epoch 4/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 403ms/step - accuracy: 0.4298 - loss: 1.2591 - val_accuracy: 0.5236 - val_loss: 1.1936\n",
      "Epoch 5/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 372ms/step - accuracy: 0.4484 - loss: 1.2328 - val_accuracy: 0.5047 - val_loss: 1.1622\n",
      "Epoch 6/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 365ms/step - accuracy: 0.4558 - loss: 1.2050 - val_accuracy: 0.4926 - val_loss: 1.1580\n",
      "Epoch 7/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 359ms/step - accuracy: 0.4452 - loss: 1.1990 - val_accuracy: 0.4987 - val_loss: 1.1414\n",
      "Epoch 8/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 369ms/step - accuracy: 0.4468 - loss: 1.1857 - val_accuracy: 0.5303 - val_loss: 1.1208\n",
      "Epoch 9/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 367ms/step - accuracy: 0.4697 - loss: 1.1615 - val_accuracy: 0.5040 - val_loss: 1.1025\n",
      "Epoch 10/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.4532 - loss: 1.1771 - val_accuracy: 0.5061 - val_loss: 1.0931\n",
      "Epoch 11/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.4848 - loss: 1.1469 - val_accuracy: 0.5074 - val_loss: 1.0877\n",
      "Epoch 12/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 361ms/step - accuracy: 0.4754 - loss: 1.1400 - val_accuracy: 0.5195 - val_loss: 1.0875\n",
      "Epoch 13/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 356ms/step - accuracy: 0.4870 - loss: 1.1345 - val_accuracy: 0.5121 - val_loss: 1.0885\n",
      "Epoch 14/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 378ms/step - accuracy: 0.4785 - loss: 1.1447 - val_accuracy: 0.5128 - val_loss: 1.0635\n",
      "Epoch 15/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 365ms/step - accuracy: 0.4713 - loss: 1.1497 - val_accuracy: 0.5606 - val_loss: 1.0556\n",
      "Epoch 16/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 354ms/step - accuracy: 0.5032 - loss: 1.1048 - val_accuracy: 0.5741 - val_loss: 1.0704\n",
      "Epoch 17/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 355ms/step - accuracy: 0.4779 - loss: 1.1308 - val_accuracy: 0.5377 - val_loss: 1.0463\n",
      "Epoch 18/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 362ms/step - accuracy: 0.5037 - loss: 1.1089 - val_accuracy: 0.5337 - val_loss: 1.0381\n",
      "Epoch 19/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 356ms/step - accuracy: 0.4973 - loss: 1.1057 - val_accuracy: 0.4993 - val_loss: 1.0863\n",
      "Epoch 20/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 359ms/step - accuracy: 0.4965 - loss: 1.1157 - val_accuracy: 0.5654 - val_loss: 1.0169\n",
      "Epoch 21/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.5122 - loss: 1.0964 - val_accuracy: 0.5593 - val_loss: 1.0271\n",
      "Epoch 22/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.5076 - loss: 1.0887 - val_accuracy: 0.5559 - val_loss: 1.0646\n",
      "Epoch 23/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.5240 - loss: 1.0857 - val_accuracy: 0.5512 - val_loss: 1.0055\n",
      "Epoch 24/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 367ms/step - accuracy: 0.5081 - loss: 1.0929 - val_accuracy: 0.5323 - val_loss: 1.0192\n",
      "Epoch 25/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.5132 - loss: 1.0943 - val_accuracy: 0.5627 - val_loss: 1.0259\n",
      "Epoch 26/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.5344 - loss: 1.0821 - val_accuracy: 0.5802 - val_loss: 1.0110\n",
      "Epoch 27/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.5374 - loss: 1.0604 - val_accuracy: 0.5519 - val_loss: 1.0063\n",
      "Epoch 28/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 367ms/step - accuracy: 0.5033 - loss: 1.0949 - val_accuracy: 0.5371 - val_loss: 1.0268\n",
      "Epoch 29/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.5068 - loss: 1.0841 - val_accuracy: 0.5889 - val_loss: 1.0110\n",
      "Epoch 30/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 362ms/step - accuracy: 0.5006 - loss: 1.0967 - val_accuracy: 0.5829 - val_loss: 1.0013\n",
      "Epoch 31/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.5440 - loss: 1.0473 - val_accuracy: 0.5761 - val_loss: 1.0118\n",
      "Epoch 32/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.5202 - loss: 1.0645 - val_accuracy: 0.5910 - val_loss: 0.9983\n",
      "Epoch 33/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.5231 - loss: 1.0659 - val_accuracy: 0.5748 - val_loss: 1.0148\n",
      "Epoch 34/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.5150 - loss: 1.0895 - val_accuracy: 0.5869 - val_loss: 0.9850\n",
      "Epoch 35/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 355ms/step - accuracy: 0.5250 - loss: 1.0675 - val_accuracy: 0.5485 - val_loss: 0.9889\n",
      "Epoch 36/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.5143 - loss: 1.0786 - val_accuracy: 0.5647 - val_loss: 0.9856\n",
      "Epoch 37/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 359ms/step - accuracy: 0.5371 - loss: 1.0541 - val_accuracy: 0.5869 - val_loss: 0.9796\n",
      "Epoch 38/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.5405 - loss: 1.0520 - val_accuracy: 0.5788 - val_loss: 0.9677\n",
      "Epoch 39/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 356ms/step - accuracy: 0.5390 - loss: 1.0547 - val_accuracy: 0.5916 - val_loss: 0.9646\n",
      "Epoch 40/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 356ms/step - accuracy: 0.5341 - loss: 1.0581 - val_accuracy: 0.5741 - val_loss: 0.9696\n",
      "Epoch 41/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 354ms/step - accuracy: 0.5212 - loss: 1.0632 - val_accuracy: 0.5883 - val_loss: 0.9645\n",
      "Epoch 42/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.5308 - loss: 1.0582 - val_accuracy: 0.5829 - val_loss: 0.9661\n",
      "Epoch 43/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.5321 - loss: 1.0571 - val_accuracy: 0.5472 - val_loss: 0.9902\n",
      "Epoch 44/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.5280 - loss: 1.0443 - val_accuracy: 0.6132 - val_loss: 0.9634\n",
      "Epoch 45/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.5507 - loss: 1.0436 - val_accuracy: 0.6044 - val_loss: 0.9639\n",
      "Epoch 46/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.5291 - loss: 1.0377 - val_accuracy: 0.5708 - val_loss: 0.9974\n",
      "Epoch 47/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 356ms/step - accuracy: 0.5500 - loss: 1.0178 - val_accuracy: 0.5943 - val_loss: 0.9533\n",
      "Epoch 48/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 355ms/step - accuracy: 0.5391 - loss: 1.0427 - val_accuracy: 0.5290 - val_loss: 1.0301\n",
      "Epoch 49/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.5385 - loss: 1.0461 - val_accuracy: 0.5977 - val_loss: 0.9831\n",
      "Epoch 50/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 366ms/step - accuracy: 0.5344 - loss: 1.0410 - val_accuracy: 0.6031 - val_loss: 0.9462\n",
      "Epoch 51/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.5196 - loss: 1.0579 - val_accuracy: 0.5741 - val_loss: 0.9689\n",
      "Epoch 52/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.5511 - loss: 1.0248 - val_accuracy: 0.5613 - val_loss: 0.9850\n",
      "Epoch 53/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 354ms/step - accuracy: 0.5315 - loss: 1.0588 - val_accuracy: 0.5964 - val_loss: 0.9451\n",
      "Epoch 54/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.5532 - loss: 1.0150 - val_accuracy: 0.5903 - val_loss: 0.9601\n",
      "Epoch 55/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.5427 - loss: 1.0457 - val_accuracy: 0.5842 - val_loss: 0.9602\n",
      "Epoch 56/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.5454 - loss: 1.0319 - val_accuracy: 0.5984 - val_loss: 0.9601\n",
      "Epoch 57/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 351ms/step - accuracy: 0.5574 - loss: 1.0141 - val_accuracy: 0.5923 - val_loss: 0.9469\n",
      "Epoch 58/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.5471 - loss: 1.0232 - val_accuracy: 0.5660 - val_loss: 0.9718\n",
      "Epoch 59/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.5333 - loss: 1.0263 - val_accuracy: 0.6314 - val_loss: 0.9534\n",
      "Epoch 60/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.5474 - loss: 1.0288 - val_accuracy: 0.5903 - val_loss: 0.9631\n",
      "Epoch 61/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 350ms/step - accuracy: 0.5501 - loss: 1.0261 - val_accuracy: 0.6226 - val_loss: 0.9462\n",
      "Epoch 62/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.5401 - loss: 1.0260 - val_accuracy: 0.5815 - val_loss: 0.9552\n",
      "Epoch 63/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.5562 - loss: 1.0180 - val_accuracy: 0.5701 - val_loss: 0.9914\n",
      "Epoch 64/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 361ms/step - accuracy: 0.5651 - loss: 1.0252 - val_accuracy: 0.6112 - val_loss: 0.9445\n",
      "Epoch 65/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 361ms/step - accuracy: 0.5504 - loss: 1.0145 - val_accuracy: 0.6085 - val_loss: 0.9522\n",
      "Epoch 66/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.5556 - loss: 1.0122 - val_accuracy: 0.5499 - val_loss: 1.0023\n",
      "Epoch 67/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.5562 - loss: 1.0021 - val_accuracy: 0.5775 - val_loss: 0.9549\n",
      "Epoch 68/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.5497 - loss: 1.0242 - val_accuracy: 0.5728 - val_loss: 0.9659\n",
      "Epoch 69/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 349ms/step - accuracy: 0.5377 - loss: 1.0328 - val_accuracy: 0.5687 - val_loss: 0.9686\n",
      "Epoch 70/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 355ms/step - accuracy: 0.5459 - loss: 1.0344 - val_accuracy: 0.5997 - val_loss: 0.9532\n",
      "Epoch 71/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 361ms/step - accuracy: 0.5539 - loss: 1.0173 - val_accuracy: 0.5741 - val_loss: 0.9489\n",
      "Epoch 72/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.5579 - loss: 1.0107 - val_accuracy: 0.6139 - val_loss: 0.9320\n",
      "Epoch 73/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.5405 - loss: 1.0301 - val_accuracy: 0.5930 - val_loss: 0.9563\n",
      "Epoch 74/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.5578 - loss: 1.0091 - val_accuracy: 0.5991 - val_loss: 0.9499\n",
      "Epoch 75/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 365ms/step - accuracy: 0.5599 - loss: 1.0080 - val_accuracy: 0.6098 - val_loss: 0.9284\n",
      "Epoch 76/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.5719 - loss: 0.9931 - val_accuracy: 0.6253 - val_loss: 0.9434\n",
      "Epoch 77/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 354ms/step - accuracy: 0.5443 - loss: 1.0386 - val_accuracy: 0.6119 - val_loss: 0.9481\n",
      "Epoch 78/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 359ms/step - accuracy: 0.5535 - loss: 1.0239 - val_accuracy: 0.6199 - val_loss: 0.9357\n",
      "Epoch 79/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 361ms/step - accuracy: 0.5536 - loss: 1.0004 - val_accuracy: 0.6125 - val_loss: 0.9275\n",
      "Epoch 80/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.5650 - loss: 1.0075 - val_accuracy: 0.5991 - val_loss: 0.9316\n",
      "Epoch 81/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 354ms/step - accuracy: 0.5630 - loss: 1.0060 - val_accuracy: 0.6307 - val_loss: 0.9352\n",
      "Epoch 82/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 349ms/step - accuracy: 0.5543 - loss: 1.0022 - val_accuracy: 0.6267 - val_loss: 0.9391\n",
      "Epoch 83/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.5773 - loss: 0.9852 - val_accuracy: 0.5788 - val_loss: 0.9741\n",
      "Epoch 84/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 346ms/step - accuracy: 0.5345 - loss: 1.0299 - val_accuracy: 0.5842 - val_loss: 0.9427\n",
      "Epoch 85/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 354ms/step - accuracy: 0.5624 - loss: 0.9998 - val_accuracy: 0.6139 - val_loss: 0.9327\n",
      "Epoch 86/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 354ms/step - accuracy: 0.5580 - loss: 0.9960 - val_accuracy: 0.6179 - val_loss: 0.9288\n",
      "Epoch 87/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 356ms/step - accuracy: 0.5474 - loss: 1.0172 - val_accuracy: 0.6018 - val_loss: 0.9281\n",
      "Epoch 88/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 371ms/step - accuracy: 0.5509 - loss: 1.0090 - val_accuracy: 0.6051 - val_loss: 0.9341\n",
      "Epoch 89/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.5697 - loss: 0.9865 - val_accuracy: 0.6253 - val_loss: 0.9274\n",
      "Epoch 90/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.5677 - loss: 1.0019 - val_accuracy: 0.6119 - val_loss: 0.9373\n",
      "Epoch 91/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 354ms/step - accuracy: 0.5630 - loss: 0.9940 - val_accuracy: 0.6085 - val_loss: 0.9336\n",
      "Epoch 92/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 359ms/step - accuracy: 0.5609 - loss: 1.0024 - val_accuracy: 0.5903 - val_loss: 0.9511\n",
      "Epoch 93/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 354ms/step - accuracy: 0.5546 - loss: 0.9972 - val_accuracy: 0.5802 - val_loss: 0.9582\n",
      "Epoch 94/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.5679 - loss: 0.9883 - val_accuracy: 0.6193 - val_loss: 0.9143\n",
      "Epoch 95/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.5496 - loss: 1.0166 - val_accuracy: 0.6193 - val_loss: 0.9101\n",
      "Epoch 96/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.5629 - loss: 0.9999 - val_accuracy: 0.5660 - val_loss: 0.9855\n",
      "Epoch 97/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 359ms/step - accuracy: 0.5766 - loss: 0.9825 - val_accuracy: 0.6193 - val_loss: 0.9163\n",
      "Epoch 98/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.5695 - loss: 0.9866 - val_accuracy: 0.6058 - val_loss: 0.9456\n",
      "Epoch 99/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.5726 - loss: 0.9950 - val_accuracy: 0.6280 - val_loss: 0.9089\n",
      "Epoch 100/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.5651 - loss: 0.9919 - val_accuracy: 0.6078 - val_loss: 0.9333\n",
      "Epoch 101/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 369ms/step - accuracy: 0.5838 - loss: 0.9789 - val_accuracy: 0.6368 - val_loss: 0.9083\n",
      "Epoch 102/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 369ms/step - accuracy: 0.5553 - loss: 0.9989 - val_accuracy: 0.6125 - val_loss: 0.9178\n",
      "Epoch 103/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.5614 - loss: 0.9910 - val_accuracy: 0.5721 - val_loss: 0.9746\n",
      "Epoch 104/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 367ms/step - accuracy: 0.5711 - loss: 0.9920 - val_accuracy: 0.6092 - val_loss: 0.9224\n",
      "Epoch 105/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 366ms/step - accuracy: 0.5674 - loss: 0.9897 - val_accuracy: 0.6132 - val_loss: 0.9204\n",
      "Epoch 106/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.5576 - loss: 0.9897 - val_accuracy: 0.5937 - val_loss: 0.9437\n",
      "Epoch 107/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.5789 - loss: 0.9734 - val_accuracy: 0.6031 - val_loss: 0.9298\n",
      "Epoch 108/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.5752 - loss: 0.9885 - val_accuracy: 0.6199 - val_loss: 0.9044\n",
      "Epoch 109/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.5722 - loss: 0.9996 - val_accuracy: 0.6173 - val_loss: 0.9189\n",
      "Epoch 110/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 354ms/step - accuracy: 0.5643 - loss: 0.9920 - val_accuracy: 0.6327 - val_loss: 0.9125\n",
      "Epoch 111/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.5664 - loss: 0.9901 - val_accuracy: 0.5849 - val_loss: 0.9431\n",
      "Epoch 112/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 349ms/step - accuracy: 0.5818 - loss: 0.9701 - val_accuracy: 0.6206 - val_loss: 0.9440\n",
      "Epoch 113/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.5664 - loss: 1.0035 - val_accuracy: 0.5580 - val_loss: 0.9890\n",
      "Epoch 114/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 371ms/step - accuracy: 0.5813 - loss: 0.9907 - val_accuracy: 0.6274 - val_loss: 0.9368\n",
      "Epoch 115/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.5576 - loss: 0.9923 - val_accuracy: 0.6361 - val_loss: 0.9066\n",
      "Epoch 116/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.5761 - loss: 0.9871 - val_accuracy: 0.6044 - val_loss: 0.9173\n",
      "Epoch 117/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.5936 - loss: 0.9732 - val_accuracy: 0.6119 - val_loss: 0.9124\n",
      "Epoch 118/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.5870 - loss: 0.9590 - val_accuracy: 0.6280 - val_loss: 0.9035\n",
      "Epoch 119/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 356ms/step - accuracy: 0.5706 - loss: 0.9786 - val_accuracy: 0.6065 - val_loss: 0.9306\n",
      "Epoch 120/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 356ms/step - accuracy: 0.5786 - loss: 0.9791 - val_accuracy: 0.6226 - val_loss: 0.8970\n",
      "Epoch 121/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.5724 - loss: 0.9784 - val_accuracy: 0.6307 - val_loss: 0.9033\n",
      "Epoch 122/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.5720 - loss: 0.9822 - val_accuracy: 0.5910 - val_loss: 0.9380\n",
      "Epoch 123/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.5722 - loss: 0.9822 - val_accuracy: 0.5977 - val_loss: 0.9305\n",
      "Epoch 124/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.5673 - loss: 0.9807 - val_accuracy: 0.6301 - val_loss: 0.8941\n",
      "Epoch 125/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.5756 - loss: 0.9851 - val_accuracy: 0.6065 - val_loss: 0.9131\n",
      "Epoch 126/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.5786 - loss: 0.9780 - val_accuracy: 0.6274 - val_loss: 0.9025\n",
      "Epoch 127/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 349ms/step - accuracy: 0.5837 - loss: 0.9782 - val_accuracy: 0.6199 - val_loss: 0.8982\n",
      "Epoch 128/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 355ms/step - accuracy: 0.5768 - loss: 0.9710 - val_accuracy: 0.6395 - val_loss: 0.9099\n",
      "Epoch 129/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 362ms/step - accuracy: 0.5904 - loss: 0.9748 - val_accuracy: 0.6132 - val_loss: 0.9029\n",
      "Epoch 130/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.5786 - loss: 0.9722 - val_accuracy: 0.6132 - val_loss: 0.9563\n",
      "Epoch 131/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 370ms/step - accuracy: 0.5802 - loss: 0.9893 - val_accuracy: 0.6220 - val_loss: 0.9208\n",
      "Epoch 132/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 359ms/step - accuracy: 0.5772 - loss: 0.9688 - val_accuracy: 0.6375 - val_loss: 0.8932\n",
      "Epoch 133/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.5758 - loss: 0.9821 - val_accuracy: 0.6024 - val_loss: 0.9161\n",
      "Epoch 134/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.5862 - loss: 0.9602 - val_accuracy: 0.6173 - val_loss: 0.9146\n",
      "Epoch 135/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 349ms/step - accuracy: 0.5828 - loss: 0.9773 - val_accuracy: 0.6146 - val_loss: 0.9433\n",
      "Epoch 136/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 362ms/step - accuracy: 0.5941 - loss: 0.9519 - val_accuracy: 0.6327 - val_loss: 0.8877\n",
      "Epoch 137/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 366ms/step - accuracy: 0.5779 - loss: 0.9835 - val_accuracy: 0.6348 - val_loss: 0.8817\n",
      "Epoch 138/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 362ms/step - accuracy: 0.5738 - loss: 0.9675 - val_accuracy: 0.6139 - val_loss: 0.9060\n",
      "Epoch 139/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.5838 - loss: 0.9517 - val_accuracy: 0.6193 - val_loss: 0.9168\n",
      "Epoch 140/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 355ms/step - accuracy: 0.5843 - loss: 0.9616 - val_accuracy: 0.6092 - val_loss: 0.9129\n",
      "Epoch 141/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.5566 - loss: 0.9878 - val_accuracy: 0.6557 - val_loss: 0.8894\n",
      "Epoch 142/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 349ms/step - accuracy: 0.5842 - loss: 0.9792 - val_accuracy: 0.6240 - val_loss: 0.8954\n",
      "Epoch 143/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 349ms/step - accuracy: 0.5798 - loss: 0.9622 - val_accuracy: 0.6038 - val_loss: 0.9333\n",
      "Epoch 144/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 356ms/step - accuracy: 0.5990 - loss: 0.9573 - val_accuracy: 0.6422 - val_loss: 0.9037\n",
      "Epoch 145/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.5934 - loss: 0.9534 - val_accuracy: 0.6105 - val_loss: 0.9235\n",
      "Epoch 146/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 343ms/step - accuracy: 0.5854 - loss: 0.9535 - val_accuracy: 0.6199 - val_loss: 0.9002\n",
      "Epoch 147/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 361ms/step - accuracy: 0.6079 - loss: 0.9499 - val_accuracy: 0.5896 - val_loss: 0.9554\n",
      "Epoch 148/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.5823 - loss: 0.9525 - val_accuracy: 0.6267 - val_loss: 0.9030\n",
      "Epoch 149/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 356ms/step - accuracy: 0.5900 - loss: 0.9566 - val_accuracy: 0.6469 - val_loss: 0.8785\n",
      "Epoch 150/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.5766 - loss: 0.9657 - val_accuracy: 0.6361 - val_loss: 0.8831\n",
      "Epoch 151/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.5791 - loss: 0.9666 - val_accuracy: 0.6482 - val_loss: 0.8986\n",
      "Epoch 152/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.5834 - loss: 0.9634 - val_accuracy: 0.6199 - val_loss: 0.8891\n",
      "Epoch 153/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.5880 - loss: 0.9607 - val_accuracy: 0.6274 - val_loss: 0.9094\n",
      "Epoch 154/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.5861 - loss: 0.9680 - val_accuracy: 0.6476 - val_loss: 0.8910\n",
      "Epoch 155/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.5773 - loss: 0.9800 - val_accuracy: 0.6132 - val_loss: 0.9035\n",
      "Epoch 156/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 349ms/step - accuracy: 0.5849 - loss: 0.9692 - val_accuracy: 0.6213 - val_loss: 0.8851\n",
      "Epoch 157/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 355ms/step - accuracy: 0.5792 - loss: 0.9749 - val_accuracy: 0.6206 - val_loss: 0.8880\n",
      "Epoch 158/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.5970 - loss: 0.9542 - val_accuracy: 0.6395 - val_loss: 0.8825\n",
      "Epoch 159/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.5899 - loss: 0.9418 - val_accuracy: 0.6199 - val_loss: 0.8910\n",
      "Epoch 160/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 354ms/step - accuracy: 0.5900 - loss: 0.9610 - val_accuracy: 0.6503 - val_loss: 0.8857\n",
      "Epoch 161/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.6016 - loss: 0.9478 - val_accuracy: 0.6482 - val_loss: 0.8651\n",
      "Epoch 162/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.5905 - loss: 0.9466 - val_accuracy: 0.6132 - val_loss: 0.9135\n",
      "Epoch 163/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.5899 - loss: 0.9599 - val_accuracy: 0.5923 - val_loss: 0.9335\n",
      "Epoch 164/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 349ms/step - accuracy: 0.5989 - loss: 0.9441 - val_accuracy: 0.6166 - val_loss: 0.9165\n",
      "Epoch 165/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.6120 - loss: 0.9426 - val_accuracy: 0.5889 - val_loss: 0.9430\n",
      "Epoch 166/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 349ms/step - accuracy: 0.5876 - loss: 0.9611 - val_accuracy: 0.6482 - val_loss: 0.8670\n",
      "Epoch 167/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.5939 - loss: 0.9482 - val_accuracy: 0.6132 - val_loss: 0.8958\n",
      "Epoch 168/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.5947 - loss: 0.9515 - val_accuracy: 0.6557 - val_loss: 0.8820\n",
      "Epoch 169/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.6006 - loss: 0.9463 - val_accuracy: 0.6604 - val_loss: 0.8726\n",
      "Epoch 170/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 349ms/step - accuracy: 0.5998 - loss: 0.9482 - val_accuracy: 0.5903 - val_loss: 0.9151\n",
      "Epoch 171/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.5815 - loss: 0.9568 - val_accuracy: 0.6044 - val_loss: 0.9339\n",
      "Epoch 172/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 361ms/step - accuracy: 0.5793 - loss: 0.9667 - val_accuracy: 0.6173 - val_loss: 0.8900\n",
      "Epoch 173/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 349ms/step - accuracy: 0.5966 - loss: 0.9383 - val_accuracy: 0.6287 - val_loss: 0.8844\n",
      "Epoch 174/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.5953 - loss: 0.9467 - val_accuracy: 0.6435 - val_loss: 0.8857\n",
      "Epoch 175/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.5891 - loss: 0.9481 - val_accuracy: 0.6388 - val_loss: 0.8847\n",
      "Epoch 176/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 355ms/step - accuracy: 0.5694 - loss: 0.9762 - val_accuracy: 0.6570 - val_loss: 0.8678\n",
      "Epoch 177/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.5795 - loss: 0.9527 - val_accuracy: 0.6226 - val_loss: 0.8801\n",
      "Epoch 178/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 346ms/step - accuracy: 0.6103 - loss: 0.9296 - val_accuracy: 0.6435 - val_loss: 0.8712\n",
      "Epoch 179/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.6061 - loss: 0.9520 - val_accuracy: 0.6173 - val_loss: 0.8982\n",
      "Epoch 180/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.5851 - loss: 0.9608 - val_accuracy: 0.6456 - val_loss: 0.8617\n",
      "Epoch 181/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.5933 - loss: 0.9591 - val_accuracy: 0.6469 - val_loss: 0.8629\n",
      "Epoch 182/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 355ms/step - accuracy: 0.5876 - loss: 0.9515 - val_accuracy: 0.5815 - val_loss: 0.9650\n",
      "Epoch 183/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.6046 - loss: 0.9364 - val_accuracy: 0.6287 - val_loss: 0.8873\n",
      "Epoch 184/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.5907 - loss: 0.9357 - val_accuracy: 0.6509 - val_loss: 0.8791\n",
      "Epoch 185/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 354ms/step - accuracy: 0.6145 - loss: 0.9248 - val_accuracy: 0.6274 - val_loss: 0.9061\n",
      "Epoch 186/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.5834 - loss: 0.9471 - val_accuracy: 0.6530 - val_loss: 0.8559\n",
      "Epoch 187/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.5935 - loss: 0.9458 - val_accuracy: 0.6489 - val_loss: 0.8897\n",
      "Epoch 188/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.5892 - loss: 0.9486 - val_accuracy: 0.6617 - val_loss: 0.8623\n",
      "Epoch 189/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.6019 - loss: 0.9224 - val_accuracy: 0.6456 - val_loss: 0.8861\n",
      "Epoch 190/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.5909 - loss: 0.9540 - val_accuracy: 0.6536 - val_loss: 0.8704\n",
      "Epoch 191/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 349ms/step - accuracy: 0.6053 - loss: 0.9362 - val_accuracy: 0.6509 - val_loss: 0.8897\n",
      "Epoch 192/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.5848 - loss: 0.9614 - val_accuracy: 0.5991 - val_loss: 0.9029\n",
      "Epoch 193/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.5859 - loss: 0.9544 - val_accuracy: 0.6456 - val_loss: 0.8794\n",
      "Epoch 194/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 355ms/step - accuracy: 0.6078 - loss: 0.9284 - val_accuracy: 0.6577 - val_loss: 0.8672\n",
      "Epoch 195/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 355ms/step - accuracy: 0.5908 - loss: 0.9482 - val_accuracy: 0.6024 - val_loss: 0.9224\n",
      "Epoch 196/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.5989 - loss: 0.9368 - val_accuracy: 0.6327 - val_loss: 0.8634\n",
      "Epoch 197/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 354ms/step - accuracy: 0.6023 - loss: 0.9515 - val_accuracy: 0.6071 - val_loss: 0.9115\n",
      "Epoch 198/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.5928 - loss: 0.9410 - val_accuracy: 0.6098 - val_loss: 0.8999\n",
      "Epoch 199/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.5958 - loss: 0.9379 - val_accuracy: 0.6584 - val_loss: 0.8514\n",
      "Epoch 200/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.6164 - loss: 0.9181 - val_accuracy: 0.6011 - val_loss: 0.9251\n",
      "Epoch 201/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.6033 - loss: 0.9352 - val_accuracy: 0.6429 - val_loss: 0.8894\n",
      "Epoch 202/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.6082 - loss: 0.9319 - val_accuracy: 0.6536 - val_loss: 0.8449\n",
      "Epoch 203/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.6237 - loss: 0.9146 - val_accuracy: 0.6570 - val_loss: 0.8688\n",
      "Epoch 204/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.6084 - loss: 0.9358 - val_accuracy: 0.6179 - val_loss: 0.8916\n",
      "Epoch 205/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.6044 - loss: 0.9418 - val_accuracy: 0.6530 - val_loss: 0.8522\n",
      "Epoch 206/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.6041 - loss: 0.9176 - val_accuracy: 0.6287 - val_loss: 0.8920\n",
      "Epoch 207/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.6091 - loss: 0.9307 - val_accuracy: 0.5869 - val_loss: 0.9147\n",
      "Epoch 208/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.6028 - loss: 0.9306 - val_accuracy: 0.6354 - val_loss: 0.8689\n",
      "Epoch 209/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 349ms/step - accuracy: 0.5955 - loss: 0.9327 - val_accuracy: 0.6031 - val_loss: 0.9269\n",
      "Epoch 210/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 355ms/step - accuracy: 0.5910 - loss: 0.9545 - val_accuracy: 0.6651 - val_loss: 0.8457\n",
      "Epoch 211/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.5957 - loss: 0.9376 - val_accuracy: 0.6125 - val_loss: 0.9102\n",
      "Epoch 212/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.5955 - loss: 0.9381 - val_accuracy: 0.6516 - val_loss: 0.8754\n",
      "Epoch 213/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 349ms/step - accuracy: 0.5975 - loss: 0.9392 - val_accuracy: 0.6321 - val_loss: 0.8680\n",
      "Epoch 214/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 354ms/step - accuracy: 0.5993 - loss: 0.9228 - val_accuracy: 0.6590 - val_loss: 0.8470\n",
      "Epoch 215/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 350ms/step - accuracy: 0.6098 - loss: 0.9277 - val_accuracy: 0.6456 - val_loss: 0.8673\n",
      "Epoch 216/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 359ms/step - accuracy: 0.5987 - loss: 0.9254 - val_accuracy: 0.6354 - val_loss: 0.8970\n",
      "Epoch 217/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.6129 - loss: 0.9001 - val_accuracy: 0.6253 - val_loss: 0.8980\n",
      "Epoch 218/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 349ms/step - accuracy: 0.6085 - loss: 0.9261 - val_accuracy: 0.6146 - val_loss: 0.9084\n",
      "Epoch 219/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.6076 - loss: 0.9278 - val_accuracy: 0.6354 - val_loss: 0.8795\n",
      "Epoch 220/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 344ms/step - accuracy: 0.5895 - loss: 0.9413 - val_accuracy: 0.6186 - val_loss: 0.8823\n",
      "Epoch 221/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 354ms/step - accuracy: 0.5981 - loss: 0.9402 - val_accuracy: 0.6368 - val_loss: 0.8550\n",
      "Epoch 222/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 345ms/step - accuracy: 0.6058 - loss: 0.9284 - val_accuracy: 0.6530 - val_loss: 0.8665\n",
      "Epoch 223/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 349ms/step - accuracy: 0.6063 - loss: 0.9214 - val_accuracy: 0.6705 - val_loss: 0.8628\n",
      "Epoch 224/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.6172 - loss: 0.9260 - val_accuracy: 0.6152 - val_loss: 0.9033\n",
      "Epoch 225/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.6000 - loss: 0.9382 - val_accuracy: 0.6395 - val_loss: 0.8506\n",
      "Epoch 226/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 355ms/step - accuracy: 0.6006 - loss: 0.9274 - val_accuracy: 0.6193 - val_loss: 0.9078\n",
      "Epoch 227/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 362ms/step - accuracy: 0.6122 - loss: 0.9379 - val_accuracy: 0.6570 - val_loss: 0.8463\n",
      "Epoch 228/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 370ms/step - accuracy: 0.6140 - loss: 0.9251 - val_accuracy: 0.6442 - val_loss: 0.8509\n",
      "Epoch 229/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 367ms/step - accuracy: 0.5965 - loss: 0.9404 - val_accuracy: 0.6503 - val_loss: 0.8529\n",
      "Epoch 230/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.6145 - loss: 0.9250 - val_accuracy: 0.6260 - val_loss: 0.8799\n",
      "Epoch 231/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.6117 - loss: 0.9190 - val_accuracy: 0.6496 - val_loss: 0.8517\n",
      "Epoch 232/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 355ms/step - accuracy: 0.6079 - loss: 0.9205 - val_accuracy: 0.6179 - val_loss: 0.9046\n",
      "Epoch 233/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.5989 - loss: 0.9136 - val_accuracy: 0.6247 - val_loss: 0.8798\n",
      "Epoch 234/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 349ms/step - accuracy: 0.5996 - loss: 0.9367 - val_accuracy: 0.6536 - val_loss: 0.8460\n",
      "Epoch 235/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.6141 - loss: 0.9180 - val_accuracy: 0.6705 - val_loss: 0.8528\n",
      "Epoch 236/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.6132 - loss: 0.9206 - val_accuracy: 0.6260 - val_loss: 0.8619\n",
      "Epoch 237/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.6011 - loss: 0.9290 - val_accuracy: 0.6287 - val_loss: 0.8833\n",
      "Epoch 238/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.6147 - loss: 0.9236 - val_accuracy: 0.6078 - val_loss: 0.9204\n",
      "Epoch 239/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.6121 - loss: 0.9140 - val_accuracy: 0.6327 - val_loss: 0.8753\n",
      "Epoch 240/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 359ms/step - accuracy: 0.6199 - loss: 0.9164 - val_accuracy: 0.6557 - val_loss: 0.8367\n",
      "Epoch 241/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.6154 - loss: 0.9192 - val_accuracy: 0.6678 - val_loss: 0.8464\n",
      "Epoch 242/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.6148 - loss: 0.9169 - val_accuracy: 0.6327 - val_loss: 0.9002\n",
      "Epoch 243/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.6144 - loss: 0.9113 - val_accuracy: 0.6354 - val_loss: 0.8753\n",
      "Epoch 244/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 362ms/step - accuracy: 0.6161 - loss: 0.9012 - val_accuracy: 0.6476 - val_loss: 0.8494\n",
      "Epoch 245/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 359ms/step - accuracy: 0.6094 - loss: 0.9147 - val_accuracy: 0.6482 - val_loss: 0.8525\n",
      "Epoch 246/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 359ms/step - accuracy: 0.6203 - loss: 0.9000 - val_accuracy: 0.6456 - val_loss: 0.8587\n",
      "Epoch 247/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 355ms/step - accuracy: 0.6106 - loss: 0.9206 - val_accuracy: 0.6624 - val_loss: 0.8383\n",
      "Epoch 248/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 355ms/step - accuracy: 0.6270 - loss: 0.9042 - val_accuracy: 0.6462 - val_loss: 0.8679\n",
      "Epoch 249/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 370ms/step - accuracy: 0.5934 - loss: 0.9321 - val_accuracy: 0.6658 - val_loss: 0.8248\n",
      "Epoch 250/250\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.6158 - loss: 0.9171 - val_accuracy: 0.6280 - val_loss: 0.9043\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 20:57:25.724989: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_15690', 76 bytes spill stores, 76 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 643ms/step - accuracy: 0.3646 - loss: 55.1978 - val_accuracy: 0.2406 - val_loss: 18.0978\n",
      "Epoch 2/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.7711 - loss: 1.7019 - val_accuracy: 0.2487 - val_loss: 50.3445\n",
      "Epoch 3/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 362ms/step - accuracy: 0.8241 - loss: 0.9426 - val_accuracy: 0.2466 - val_loss: 36.5525\n",
      "Epoch 4/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 356ms/step - accuracy: 0.8604 - loss: 0.5930 - val_accuracy: 0.2487 - val_loss: 36.2223\n",
      "Epoch 5/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 379ms/step - accuracy: 0.8902 - loss: 0.4337 - val_accuracy: 0.3322 - val_loss: 15.4449\n",
      "Epoch 6/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.8915 - loss: 0.4097 - val_accuracy: 0.6226 - val_loss: 3.2327\n",
      "Epoch 7/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 362ms/step - accuracy: 0.9238 - loss: 0.2795 - val_accuracy: 0.8544 - val_loss: 0.5977\n",
      "Epoch 8/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 370ms/step - accuracy: 0.9300 - loss: 0.2471 - val_accuracy: 0.8969 - val_loss: 0.3714\n",
      "Epoch 9/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 365ms/step - accuracy: 0.9389 - loss: 0.2134 - val_accuracy: 0.9400 - val_loss: 0.1913\n",
      "Epoch 10/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 372ms/step - accuracy: 0.9545 - loss: 0.1428 - val_accuracy: 0.9501 - val_loss: 0.1736\n",
      "Epoch 11/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 369ms/step - accuracy: 0.9535 - loss: 0.1412 - val_accuracy: 0.9515 - val_loss: 0.1636\n",
      "Epoch 12/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.9551 - loss: 0.1156 - val_accuracy: 0.9488 - val_loss: 0.1708\n",
      "Epoch 13/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 362ms/step - accuracy: 0.9592 - loss: 0.1196 - val_accuracy: 0.9522 - val_loss: 0.1563\n",
      "Epoch 14/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 356ms/step - accuracy: 0.9598 - loss: 0.1155 - val_accuracy: 0.9596 - val_loss: 0.1636\n",
      "Epoch 15/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 361ms/step - accuracy: 0.9691 - loss: 0.0989 - val_accuracy: 0.9629 - val_loss: 0.1287\n",
      "Epoch 16/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 359ms/step - accuracy: 0.9706 - loss: 0.1048 - val_accuracy: 0.9616 - val_loss: 0.1290\n",
      "Epoch 17/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 373ms/step - accuracy: 0.9776 - loss: 0.0774 - val_accuracy: 0.9717 - val_loss: 0.1083\n",
      "Epoch 18/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.9734 - loss: 0.0759 - val_accuracy: 0.9717 - val_loss: 0.1119\n",
      "Epoch 19/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 361ms/step - accuracy: 0.9760 - loss: 0.0669 - val_accuracy: 0.9697 - val_loss: 0.1048\n",
      "Epoch 20/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 368ms/step - accuracy: 0.9816 - loss: 0.0509 - val_accuracy: 0.9690 - val_loss: 0.1012\n",
      "Epoch 21/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 387ms/step - accuracy: 0.9845 - loss: 0.0484 - val_accuracy: 0.9764 - val_loss: 0.0724\n",
      "Epoch 22/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.9841 - loss: 0.0440 - val_accuracy: 0.9757 - val_loss: 0.0864\n",
      "Epoch 23/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.9812 - loss: 0.0493 - val_accuracy: 0.9744 - val_loss: 0.0949\n",
      "Epoch 24/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 369ms/step - accuracy: 0.9855 - loss: 0.0423 - val_accuracy: 0.9778 - val_loss: 0.0687\n",
      "Epoch 25/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 365ms/step - accuracy: 0.9850 - loss: 0.0474 - val_accuracy: 0.9798 - val_loss: 0.0639\n",
      "Epoch 26/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.9870 - loss: 0.0301 - val_accuracy: 0.9697 - val_loss: 0.0992\n",
      "Epoch 27/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.9833 - loss: 0.0496 - val_accuracy: 0.9832 - val_loss: 0.0694\n",
      "Epoch 28/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 364ms/step - accuracy: 0.9901 - loss: 0.0276 - val_accuracy: 0.9825 - val_loss: 0.0608\n",
      "Epoch 29/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.9869 - loss: 0.0425 - val_accuracy: 0.9811 - val_loss: 0.0701\n",
      "Epoch 30/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.9928 - loss: 0.0231 - val_accuracy: 0.9730 - val_loss: 0.1268\n",
      "Epoch 31/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.9885 - loss: 0.0448 - val_accuracy: 0.9899 - val_loss: 0.0583\n",
      "Epoch 32/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 348ms/step - accuracy: 0.9899 - loss: 0.0369 - val_accuracy: 0.9832 - val_loss: 0.0684\n",
      "Epoch 33/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 362ms/step - accuracy: 0.9927 - loss: 0.0272 - val_accuracy: 0.9858 - val_loss: 0.0521\n",
      "Epoch 34/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 356ms/step - accuracy: 0.9904 - loss: 0.0308 - val_accuracy: 0.9555 - val_loss: 0.3238\n",
      "Epoch 35/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 355ms/step - accuracy: 0.9897 - loss: 0.0404 - val_accuracy: 0.9825 - val_loss: 0.0614\n",
      "Epoch 36/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.9915 - loss: 0.0262 - val_accuracy: 0.9852 - val_loss: 0.0540\n",
      "Epoch 37/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.9887 - loss: 0.0326 - val_accuracy: 0.9832 - val_loss: 0.0589\n",
      "Epoch 38/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.9928 - loss: 0.0202 - val_accuracy: 0.9845 - val_loss: 0.0530\n",
      "Epoch 39/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.9953 - loss: 0.0179 - val_accuracy: 0.9818 - val_loss: 0.0670\n",
      "Epoch 40/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.9937 - loss: 0.0168 - val_accuracy: 0.9737 - val_loss: 0.0952\n",
      "Epoch 41/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.9962 - loss: 0.0175 - val_accuracy: 0.9791 - val_loss: 0.0861\n",
      "Epoch 42/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.9931 - loss: 0.0156 - val_accuracy: 0.9811 - val_loss: 0.0929\n",
      "Epoch 43/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.9903 - loss: 0.0265 - val_accuracy: 0.9845 - val_loss: 0.0755\n",
      "Epoch 44/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 354ms/step - accuracy: 0.9947 - loss: 0.0173 - val_accuracy: 0.9805 - val_loss: 0.0557\n",
      "Epoch 45/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.9939 - loss: 0.0173 - val_accuracy: 0.9784 - val_loss: 0.0730\n",
      "Epoch 46/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.9946 - loss: 0.0131 - val_accuracy: 0.9906 - val_loss: 0.0380\n",
      "Epoch 47/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 359ms/step - accuracy: 0.9956 - loss: 0.0158 - val_accuracy: 0.9872 - val_loss: 0.0591\n",
      "Epoch 48/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 355ms/step - accuracy: 0.9925 - loss: 0.0224 - val_accuracy: 0.9805 - val_loss: 0.0826\n",
      "Epoch 49/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.9933 - loss: 0.0181 - val_accuracy: 0.9885 - val_loss: 0.0561\n",
      "Epoch 50/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 365ms/step - accuracy: 0.9954 - loss: 0.0137 - val_accuracy: 0.9879 - val_loss: 0.0324\n",
      "Epoch 51/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 349ms/step - accuracy: 0.9940 - loss: 0.0151 - val_accuracy: 0.9845 - val_loss: 0.0692\n",
      "Epoch 52/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.9933 - loss: 0.0307 - val_accuracy: 0.9724 - val_loss: 0.1281\n",
      "Epoch 53/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.9904 - loss: 0.0319 - val_accuracy: 0.9852 - val_loss: 0.0659\n",
      "Epoch 54/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.9941 - loss: 0.0230 - val_accuracy: 0.9811 - val_loss: 0.0767\n",
      "Epoch 55/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.9981 - loss: 0.0067 - val_accuracy: 0.9643 - val_loss: 0.3726\n",
      "Epoch 56/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.9936 - loss: 0.0235 - val_accuracy: 0.9811 - val_loss: 0.0781\n",
      "Epoch 57/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.9959 - loss: 0.0086 - val_accuracy: 0.9919 - val_loss: 0.0481\n",
      "Epoch 58/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 354ms/step - accuracy: 0.9939 - loss: 0.0179 - val_accuracy: 0.9791 - val_loss: 0.1028\n",
      "Epoch 59/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 349ms/step - accuracy: 0.9968 - loss: 0.0116 - val_accuracy: 0.9832 - val_loss: 0.0669\n",
      "Epoch 60/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.9952 - loss: 0.0125 - val_accuracy: 0.9872 - val_loss: 0.0525\n",
      "Epoch 61/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.9974 - loss: 0.0120 - val_accuracy: 0.9865 - val_loss: 0.0709\n",
      "Epoch 62/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 362ms/step - accuracy: 0.9956 - loss: 0.0129 - val_accuracy: 0.9912 - val_loss: 0.0414\n",
      "Epoch 63/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 359ms/step - accuracy: 0.9944 - loss: 0.0133 - val_accuracy: 0.9858 - val_loss: 0.0731\n",
      "Epoch 64/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.9966 - loss: 0.0101 - val_accuracy: 0.9899 - val_loss: 0.0451\n",
      "Epoch 65/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.9969 - loss: 0.0099 - val_accuracy: 0.9892 - val_loss: 0.0600\n",
      "Epoch 66/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 365ms/step - accuracy: 0.9973 - loss: 0.0069 - val_accuracy: 0.9879 - val_loss: 0.0654\n",
      "Epoch 67/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.9968 - loss: 0.0071 - val_accuracy: 0.9872 - val_loss: 0.0713\n",
      "Epoch 68/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 360ms/step - accuracy: 0.9951 - loss: 0.0210 - val_accuracy: 0.9805 - val_loss: 0.1511\n",
      "Epoch 69/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 356ms/step - accuracy: 0.9953 - loss: 0.0119 - val_accuracy: 0.9845 - val_loss: 0.0731\n",
      "Epoch 70/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 356ms/step - accuracy: 0.9972 - loss: 0.0060 - val_accuracy: 0.9825 - val_loss: 0.0813\n",
      "Epoch 71/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 349ms/step - accuracy: 0.9961 - loss: 0.0108 - val_accuracy: 0.9879 - val_loss: 0.0552\n",
      "Epoch 72/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 355ms/step - accuracy: 0.9945 - loss: 0.0308 - val_accuracy: 0.9879 - val_loss: 0.0514\n",
      "Epoch 73/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 361ms/step - accuracy: 0.9942 - loss: 0.0157 - val_accuracy: 0.9892 - val_loss: 0.0600\n",
      "Epoch 74/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 354ms/step - accuracy: 0.9977 - loss: 0.0057 - val_accuracy: 0.9865 - val_loss: 0.0567\n",
      "Epoch 75/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 356ms/step - accuracy: 0.9958 - loss: 0.0171 - val_accuracy: 0.9885 - val_loss: 0.0678\n",
      "Epoch 76/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 355ms/step - accuracy: 0.9975 - loss: 0.0068 - val_accuracy: 0.9912 - val_loss: 0.0445\n",
      "Epoch 77/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.9969 - loss: 0.0067 - val_accuracy: 0.9858 - val_loss: 0.0652\n",
      "Epoch 78/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 349ms/step - accuracy: 0.9972 - loss: 0.0062 - val_accuracy: 0.9892 - val_loss: 0.0462\n",
      "Epoch 79/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 354ms/step - accuracy: 0.9970 - loss: 0.0136 - val_accuracy: 0.9818 - val_loss: 0.1078\n",
      "Epoch 80/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.9959 - loss: 0.0140 - val_accuracy: 0.9899 - val_loss: 0.0530\n",
      "Epoch 81/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 350ms/step - accuracy: 0.9976 - loss: 0.0075 - val_accuracy: 0.9906 - val_loss: 0.0530\n",
      "Epoch 82/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.9975 - loss: 0.0059 - val_accuracy: 0.9872 - val_loss: 0.0608\n",
      "Epoch 83/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.9991 - loss: 0.0038 - val_accuracy: 0.9912 - val_loss: 0.0467\n",
      "Epoch 84/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 356ms/step - accuracy: 0.9970 - loss: 0.0122 - val_accuracy: 0.9879 - val_loss: 0.0613\n",
      "Epoch 85/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 353ms/step - accuracy: 0.9985 - loss: 0.0055 - val_accuracy: 0.9811 - val_loss: 0.1128\n",
      "Epoch 86/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.9963 - loss: 0.0102 - val_accuracy: 0.9858 - val_loss: 0.0633\n",
      "Epoch 87/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.9988 - loss: 0.0036 - val_accuracy: 0.9852 - val_loss: 0.0749\n",
      "Epoch 88/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 351ms/step - accuracy: 0.9988 - loss: 0.0041 - val_accuracy: 0.9899 - val_loss: 0.0447\n",
      "Epoch 89/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 349ms/step - accuracy: 0.9971 - loss: 0.0061 - val_accuracy: 0.9818 - val_loss: 0.0903\n",
      "Epoch 90/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.9980 - loss: 0.0035 - val_accuracy: 0.9892 - val_loss: 0.0533\n",
      "Epoch 91/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 347ms/step - accuracy: 0.9985 - loss: 0.0037 - val_accuracy: 0.9885 - val_loss: 0.0642\n",
      "Epoch 92/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.9977 - loss: 0.0065 - val_accuracy: 0.9892 - val_loss: 0.0663\n",
      "Epoch 93/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 356ms/step - accuracy: 0.9966 - loss: 0.0089 - val_accuracy: 0.9885 - val_loss: 0.0673\n",
      "Epoch 94/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.9990 - loss: 0.0074 - val_accuracy: 0.9899 - val_loss: 0.0472\n",
      "Epoch 95/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 357ms/step - accuracy: 0.9987 - loss: 0.0053 - val_accuracy: 0.9845 - val_loss: 0.0803\n",
      "Epoch 96/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 363ms/step - accuracy: 0.9982 - loss: 0.0053 - val_accuracy: 0.9885 - val_loss: 0.0843\n",
      "Epoch 97/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 354ms/step - accuracy: 0.9985 - loss: 0.0056 - val_accuracy: 0.9865 - val_loss: 0.1121\n",
      "Epoch 98/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 352ms/step - accuracy: 0.9968 - loss: 0.0090 - val_accuracy: 0.9899 - val_loss: 0.0669\n",
      "Epoch 99/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - accuracy: 0.9978 - loss: 0.0034 - val_accuracy: 0.9899 - val_loss: 0.0671\n",
      "Epoch 100/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 354ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 0.9892 - val_loss: 0.0831\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set paths to your dataset folders\n",
    "train_dir = '/home/esidserver/datasets/testing_cls/training-v2/train/'\n",
    "val_dir = '/home/esidserver/datasets/testing_cls/training-v2/val/'\n",
    "test_dir = '/home/esidserver/datasets/testing_cls/training-v2/test/'\n",
    "\n",
    "# Image data generator with data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Data generator for validation and test\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Data loaders\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Important for confusion matrix\n",
    ")\n",
    "\n",
    "# Load the ResNet-50 model with pre-trained weights\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom top layers for classification\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping and model checkpoint\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('resnet50_best_model.keras', save_best_only=True, monitor='val_loss')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=250,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "\n",
    "# Fine-tuning: Unfreeze some layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compile the model again\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Continue training with fine-tuning\n",
    "history_finetune = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - accuracy: 0.9859 - loss: 0.0250 \n",
      "Final Validation Accuracy: 0.9879, Validation Loss: 0.0324\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.8655 - loss: 0.8443"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 22:40:06.311816: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1719', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 284ms/step - accuracy: 0.8698 - loss: 0.8238\n",
      "Test Accuracy: 0.9189, Test Loss: 0.5884\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate on the validation set\n",
    "val_loss, val_acc = model.evaluate(val_generator)\n",
    "print(f\"Final Validation Accuracy: {val_acc:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Save the final model\n",
    "model.save('resnet50_final_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 279ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AB       0.95      0.82      0.88       188\n",
      "          AG       0.87      0.86      0.86       184\n",
      "         ANO       0.99      1.00      1.00       184\n",
      "          CQ       0.87      0.99      0.93       184\n",
      "\n",
      "    accuracy                           0.92       740\n",
      "   macro avg       0.92      0.92      0.92       740\n",
      "weighted avg       0.92      0.92      0.92       740\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Generate predictions for the test set\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Get true labels\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "cm_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=cm_labels, yticklabels=cm_labels)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report for precision, recall, f1-score\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred_classes, target_names=cm_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
